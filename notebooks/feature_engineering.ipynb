{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed28675a",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae38ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../processed_data/companies_cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90bc783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196530, 47)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b3ec41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'normalized_name', 'country_code', 'state_code', 'city',\n",
       "       'region', 'lat', 'lng', 'status', 'category_code',\n",
       "       'category_code_clean', 'description', 'overview', 'tag_list',\n",
       "       'founded_year', 'founding_era', 'company_age_years', 'age_group',\n",
       "       'funding_total_usd', 'funding_rounds', 'has_funding',\n",
       "       'first_funding_at', 'last_funding_at', 'days_to_first_funding',\n",
       "       'months_to_first_funding', 'months_since_last_funding',\n",
       "       'funding_velocity_category', 'funding_recency', 'milestones',\n",
       "       'first_milestone_at', 'last_milestone_at', 'investment_rounds',\n",
       "       'invested_companies', 'relationships', 'homepage_url', 'domain',\n",
       "       'twitter_username', 'logo_url', 'failure_risk', 'risk_tier',\n",
       "       'risk_tier_label', 'under_capitalized', 'created_at', 'created_by',\n",
       "       'updated_at', 'closed_at'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d12bebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'name', 'normalized_name', 'country_code', 'state_code', 'city',\n",
      "       'region', 'lat', 'lng', 'status', 'category_code',\n",
      "       'category_code_clean', 'description', 'overview', 'tag_list',\n",
      "       'founded_year', 'founding_era', 'company_age_years', 'age_group',\n",
      "       'funding_total_usd', 'funding_rounds', 'has_funding',\n",
      "       'first_funding_at', 'last_funding_at', 'days_to_first_funding',\n",
      "       'months_to_first_funding', 'months_since_last_funding',\n",
      "       'funding_velocity_category', 'funding_recency', 'milestones',\n",
      "       'first_milestone_at', 'last_milestone_at', 'investment_rounds',\n",
      "       'invested_companies', 'relationships', 'homepage_url', 'domain',\n",
      "       'twitter_username', 'logo_url', 'failure_risk', 'risk_tier',\n",
      "       'risk_tier_label', 'under_capitalized', 'created_at', 'created_by',\n",
      "       'updated_at', 'closed_at'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df['funding_velocity'] = df['funding_total_usd'] / df['company_age_years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0616d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funding_total_usd / avg_funding_in_category\n",
    "total_avg_funding = df['funding_total_usd'].mean()\n",
    "df['funding_vs_avg'] = df['funding_total_usd'] / total_avg_funding\n",
    "\n",
    "category_avg_funding = df.groupby('category_code')['funding_total_usd'].transform('mean')\n",
    "df['funding_vs_industry_avg'] = df['funding_total_usd'] / np.where(\n",
    "    df['category_code'].isna(),\n",
    "    total_avg_funding,\n",
    "    category_avg_funding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b655e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket by founding year\n",
    "def categorize_founding_year(year):\n",
    "    if year <= 1990:\n",
    "        return \"Pre-1990\"\n",
    "    elif year <= 2000:\n",
    "        return \"1991-2000\"\n",
    "    elif year <= 2008:\n",
    "        return \"2001-2008\"\n",
    "    else:\n",
    "        return \"2009-2014\"\n",
    "\n",
    "df[\"founding_era\"] = df[\"founded_year\"].apply(categorize_founding_year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea1b005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate funding stage by total amount of funding and company status\n",
    "def funding_stage(row):\n",
    "    f = row['funding_total_usd']\n",
    "    s = row['status']\n",
    "    \n",
    "    if s == 'closed':\n",
    "        return 'Closed'\n",
    "    elif s == 'acquired':\n",
    "        return 'Exit (Acquired)'\n",
    "    elif s == 'ipo':\n",
    "        return 'Exit (IPO)'\n",
    "    \n",
    "    if f < 1e6:\n",
    "        return 'Pre-seed'\n",
    "    elif f < 10e6:\n",
    "        return 'Seed'\n",
    "    elif f < 15e6:\n",
    "        return 'Early'\n",
    "    elif f < 100e6:\n",
    "        return 'Growth'\n",
    "    else:\n",
    "        return 'Late'\n",
    "    \n",
    "df['funding_stage'] = df.apply(funding_stage, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cd2c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# industry growth index\n",
    "\n",
    "industry_stats = (\n",
    "    df.groupby(['category_code', 'founded_year'])\n",
    "      .agg(\n",
    "          num_startups=('id', 'count'),\n",
    "          total_funding=('funding_total_usd', 'sum')\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "industry_stats['num_startups_norm'] = industry_stats.groupby('category_code')['num_startups'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min())\n",
    ")\n",
    "industry_stats['total_funding_norm'] = industry_stats.groupby('category_code')['total_funding'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min())\n",
    ")\n",
    "\n",
    "industry_stats['industry_growth_index'] = (\n",
    "    0.5 * industry_stats['num_startups_norm'] +\n",
    "    0.5 * industry_stats['total_funding_norm']\n",
    ")\n",
    "\n",
    "df = df.merge(\n",
    "    industry_stats[['category_code', 'founded_year', 'industry_growth_index']],\n",
    "    on=['category_code', 'founded_year'],\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc555599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# industry growth rate\n",
    "industry_stats['industry_growth_rate'] = industry_stats.groupby('category_code')['industry_growth_index'].pct_change()\n",
    "\n",
    "df = df.merge(\n",
    "    industry_stats[['category_code', 'founded_year', 'industry_growth_rate']],\n",
    "    on=['category_code', 'founded_year'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c580245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate risk by country/region\n",
    "country_risk = df.groupby('country_code')['failure_risk'].agg(['mean', 'std', 'count']).reset_index()\n",
    "country_risk.columns = ['country_code', 'country_risk_mean', 'country_risk_std', 'country_count']\n",
    "country_risk['country_risk_confidence'] = country_risk['country_count'] / country_risk['country_count'].max()\n",
    "country_risk_mean = country_risk['country_risk_mean'].mean()\n",
    "\n",
    "df = df.merge(country_risk[['country_code', 'country_risk_mean', 'country_risk_confidence']], \n",
    "              on='country_code', how='left')\n",
    "\n",
    "# Fill missing values with global average\n",
    "global_risk_mean = df['failure_risk'].mean()\n",
    "if 'country_risk_mean' not in df.columns:\n",
    "    df['country_risk_mean'] = global_risk_mean\n",
    "else:\n",
    "    df['country_risk_mean'] = df['country_risk_mean'].fillna(global_risk_mean)\n",
    "\n",
    "if 'country_risk_confidence' not in df.columns:\n",
    "    df['country_risk_confidence'] = 0.1\n",
    "else:\n",
    "    df['country_risk_confidence'] = df['country_risk_confidence'].fillna(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4cf7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate risk by industry\n",
    "industry_risk = df.groupby('category_code')['failure_risk'].agg(['mean', 'std', 'count']).reset_index()\n",
    "industry_risk.columns = ['category_code', 'industry_risk_mean', 'industry_risk_std', 'industry_count']\n",
    "industry_risk['industry_risk_confidence'] = industry_risk['industry_count'] / industry_risk['industry_count'].max()\n",
    "\n",
    "df = df.merge(industry_risk[['category_code', 'industry_risk_mean', 'industry_risk_confidence']], \n",
    "              on='category_code', how='left')\n",
    "\n",
    "# Fill missing values\n",
    "df['industry_risk_mean'] = df['industry_risk_mean'].fillna(global_risk_mean)\n",
    "df['industry_risk_confidence'] = df['industry_risk_confidence'].fillna(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e84e2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate risk by funding stage\n",
    "stage_risk = df.groupby('funding_stage')['failure_risk'].agg(['mean', 'count']).reset_index()\n",
    "stage_risk.columns = ['funding_stage', 'stage_risk_mean', 'stage_count']\n",
    "\n",
    "df = df.merge(stage_risk[['funding_stage', 'stage_risk_mean']], on='funding_stage', how='left')\n",
    "df['stage_risk_mean'] = df['stage_risk_mean'].fillna(global_risk_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34ec1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age × Funding interactions\n",
    "df['age_funding_ratio'] = df['company_age_years'] * df['funding_vs_avg']\n",
    "df['age_funding_velocity'] = df['company_age_years'] * df['funding_velocity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cffda33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic × Industry interactions\n",
    "df['geo_industry_risk'] = df['country_risk_mean'] * df['industry_risk_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e265ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funding × Industry interactions\n",
    "df['funding_industry_fit'] = df['funding_vs_industry_avg'] * df['industry_growth_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "831f4732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age × Industry maturity\n",
    "df['age_industry_maturity'] = df['company_age_years'] * df['industry_growth_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6334c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experience-based risk score\n",
    "df['experience_risk_score'] = (\n",
    "    0.5 * (df['company_age_years'] / df['company_age_years'].max()) +  # Normalized age\n",
    "    0.3 * df['country_risk_confidence'] +  # Geographic experience\n",
    "    0.2 * df['industry_risk_confidence']   # Industry experience\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40836992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years since founding (for survival analysis perspective)\n",
    "current_year = 2025\n",
    "df['years_since_founding'] = current_year - df['founded_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa2480ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funding efficiency relative to company age\n",
    "df['funding_efficiency'] = df['funding_total_usd'] / (df['company_age_years'] + 1)  # +1 to avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "826e2982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funding momentum (how much above/below expected for age)\n",
    "age_funding_median = df.groupby('company_age_years')['funding_total_usd'].transform('median')\n",
    "df['funding_momentum'] = df['funding_total_usd'] / (age_funding_median + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18ea283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funding relative to founding era\n",
    "era_funding_median = df.groupby('founding_era')['funding_total_usd'].transform('median')\n",
    "df['era_adjusted_funding'] = df['funding_total_usd'] / (era_funding_median + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35e062cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competitive landscape intensity\n",
    "industry_competition = df.groupby(['category_code', 'founded_year']).size().reset_index(name='industry_competition')\n",
    "df = df.merge(industry_competition, on=['category_code', 'founded_year'], how='left')\n",
    "df['industry_competition'] = df['industry_competition'].fillna(df['industry_competition'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3a804c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic market saturation\n",
    "geo_saturation = df.groupby(['country_code', 'founded_year']).size().reset_index(name='geo_market_saturation')\n",
    "df = df.merge(geo_saturation, on=['country_code', 'founded_year'], how='left')\n",
    "df['geo_market_saturation'] = df['geo_market_saturation'].fillna(df['geo_market_saturation'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "892d46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk deviation from peers\n",
    "df['risk_vs_country_peers'] = df['failure_risk'] - df['country_risk_mean']\n",
    "df['risk_vs_industry_peers'] = df['failure_risk'] - df['industry_risk_mean']\n",
    "df['risk_vs_stage_peers'] = df['failure_risk'] - df['stage_risk_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a979acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funding deviation from expectations\n",
    "df['funding_vs_age_expectation'] = df['funding_total_usd'] - age_funding_median\n",
    "df['funding_vs_era_expectation'] = df['funding_total_usd'] - era_funding_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35a859a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite peer comparison score\n",
    "df['peer_performance_score'] = (\n",
    "    0.4 * (-df['risk_vs_industry_peers']) +  # Lower risk vs peers = better\n",
    "    0.3 * df['funding_vs_industry_avg'] +   # Higher funding vs industry = better\n",
    "    0.3 * (-df['risk_vs_country_peers'])    # Lower risk vs country = better\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13eabc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investment activity level\n",
    "df['investment_activity_score'] = (\n",
    "    0.6 * (df['investment_rounds'] / (df['investment_rounds'].max() + 1)) +\n",
    "    0.4 * (df['invested_companies'] / (df['invested_companies'].max() + 1))\n",
    ")\n",
    "\n",
    "# Investment to funding ratio (investment activity vs seeking funding)\n",
    "df['investment_to_funding_ratio'] = df['investment_rounds'] / (df['funding_rounds'] + 1)\n",
    "\n",
    "# Network effect proxy - convert relationships to numeric first\n",
    "df['relationships_count'] = pd.to_numeric(df['relationships'], errors='coerce').fillna(0)\n",
    "df['network_connectivity'] = df['investment_rounds'] + df['invested_companies'] + df['relationships_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f6598fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milestones per year of existence\n",
    "df['milestones_per_year'] = df['milestones'] / (df['company_age_years'] + 1)\n",
    "\n",
    "# Companies with high milestone activity\n",
    "df['is_milestone_active'] = (df['milestones'] >= df['milestones'].quantile(0.75)).astype(int)\n",
    "\n",
    "# Achievement score (combination of milestones and funding success)\n",
    "df['achievement_score'] = (\n",
    "    0.4 * (df['milestones'] / (df['milestones'].max() + 1)) +\n",
    "    0.3 * (df['funding_rounds'] / (df['funding_rounds'].max() + 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b918acd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Companies with domains: 196,530\n",
      "  - Companies with Twitter: 196,530\n"
     ]
    }
   ],
   "source": [
    "# Basic digital presence indicators\n",
    "df['has_domain'] = (df['domain'] != 'None').astype(int)\n",
    "df['has_twitter'] = (df['twitter_username'] != 'None').astype(int)\n",
    "df['has_logo'] = (df['logo_url'].notna()).astype(int)\n",
    "\n",
    "# Digital presence score\n",
    "df['digital_presence_score'] = (\n",
    "    0.4 * df['has_domain'] +\n",
    "    0.3 * df['has_twitter'] +\n",
    "    0.3 * df['has_logo']\n",
    ")\n",
    "\n",
    "# Extract domain insights\n",
    "def extract_domain_features(row):\n",
    "    domain = row['domain']\n",
    "    if domain == 'None' or pd.isna(domain):\n",
    "        return 'none', 0, 0\n",
    "    \n",
    "    # Domain type\n",
    "    if any(ext in domain.lower() for ext in ['.gov', '.edu', '.org']):\n",
    "        domain_type = 'institutional'\n",
    "    elif any(ext in domain.lower() for ext in ['.com', '.net', '.biz']):\n",
    "        domain_type = 'commercial'\n",
    "    else:\n",
    "        domain_type = 'other'\n",
    "    \n",
    "    # Domain complexity\n",
    "    domain_length = len(domain)\n",
    "    subdomain_count = domain.count('.') - 1  # Subtract 1 for the main domain\n",
    "    \n",
    "    return domain_type, domain_length, subdomain_count\n",
    "\n",
    "# Apply domain feature extraction\n",
    "domain_features = df.apply(extract_domain_features, axis=1, result_type='expand')\n",
    "df['domain_type'] = domain_features[0]\n",
    "df['domain_length'] = domain_features[1]\n",
    "df['subdomain_count'] = domain_features[2]\n",
    "\n",
    "print(f\"  - Companies with domains: {df['has_domain'].sum():,}\")\n",
    "print(f\"  - Companies with Twitter: {df['has_twitter'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "343d9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content availability\n",
    "df['has_description'] = (df['description'] != 'Unknown').astype(int)\n",
    "df['has_overview'] = (df['overview'] != 'Unknown').astype(int)\n",
    "df['has_tags'] = (df['tag_list'] != 'Unknown').astype(int)\n",
    "\n",
    "# Content richness score\n",
    "df['content_richness'] = df['has_description'] + df['has_overview'] + df['has_tags']\n",
    "\n",
    "# Description length analysis\n",
    "def safe_len(text):\n",
    "    if text == 'Unknown' or pd.isna(text):\n",
    "        return 0\n",
    "    return len(str(text))\n",
    "\n",
    "df['description_length'] = df['description'].apply(safe_len)\n",
    "df['overview_length'] = df['overview'].apply(safe_len)\n",
    "\n",
    "# Tag analysis\n",
    "def analyze_tags(tag_string):\n",
    "    if tag_string == 'Unknown' or pd.isna(tag_string):\n",
    "        return 0, 0\n",
    "    \n",
    "    tags = str(tag_string).split(',')\n",
    "    tag_count = len(tags)\n",
    "    avg_tag_length = sum(len(tag.strip()) for tag in tags) / tag_count if tag_count > 0 else 0\n",
    "    \n",
    "    return tag_count, avg_tag_length\n",
    "\n",
    "tag_features = df['tag_list'].apply(analyze_tags)\n",
    "df['tag_count'] = [x[0] for x in tag_features]\n",
    "df['avg_tag_length'] = [x[1] for x in tag_features]\n",
    "\n",
    "# Text sophistication score\n",
    "df['text_sophistication'] = (\n",
    "    0.3 * (df['description_length'] / (df['description_length'].max() + 1)) +\n",
    "    0.3 * (df['overview_length'] / (df['overview_length'].max() + 1)) +\n",
    "    0.4 * (df['tag_count'] / (df['tag_count'].max() + 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3279a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "date_cols = ['first_funding_at', 'last_funding_at', 'first_milestone_at', 'last_milestone_at', 'created_at', 'updated_at', 'closed_at']\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Funding timeline features\n",
    "df['funding_duration_days'] = (df['last_funding_at'] - df['first_funding_at']).dt.days\n",
    "df['funding_duration_days'] = df['funding_duration_days'].fillna(0)\n",
    "\n",
    "# Time to first funding (from founding) - check if founded_at exists, otherwise use founded_year\n",
    "if 'founded_at' in df.columns:\n",
    "    df['founded_at'] = pd.to_datetime(df['founded_at'], errors='coerce')\n",
    "    df['time_to_first_funding_days'] = (df['first_funding_at'] - df['founded_at']).dt.days\n",
    "else:\n",
    "    # Create founded_at from founded_year\n",
    "    df['founded_at_estimated'] = pd.to_datetime(df['founded_year'], format='%Y', errors='coerce')\n",
    "    df['time_to_first_funding_days'] = (df['first_funding_at'] - df['founded_at_estimated']).dt.days\n",
    "\n",
    "df['time_to_first_funding_years'] = df['time_to_first_funding_days'] / 365.25\n",
    "\n",
    "# Milestone timeline features\n",
    "df['milestone_duration_days'] = (df['last_milestone_at'] - df['first_milestone_at']).dt.days\n",
    "df['milestone_duration_days'] = df['milestone_duration_days'].fillna(0)\n",
    "\n",
    "# Activity recency (days since last update)\n",
    "current_date = pd.Timestamp.now()\n",
    "df['days_since_last_update'] = (current_date - df['updated_at']).dt.days\n",
    "df['days_since_last_funding'] = (current_date - df['last_funding_at']).dt.days\n",
    "df['days_since_last_milestone'] = (current_date - df['last_milestone_at']).dt.days\n",
    "\n",
    "# Fill NaN values for companies without funding/milestones\n",
    "df['days_since_last_funding'] = df['days_since_last_funding'].fillna(df['days_since_last_update'])\n",
    "df['days_since_last_milestone'] = df['days_since_last_milestone'].fillna(df['days_since_last_update'])\n",
    "\n",
    "# Activity frequency (avoid division by zero)\n",
    "df['funding_frequency'] = df['funding_rounds'] / (df['funding_duration_days'] / 365.25 + 1)\n",
    "df['milestone_frequency'] = df['milestones'] / (df['milestone_duration_days'] / 365.25 + 1)\n",
    "\n",
    "# Recently active flags\n",
    "df['recently_funded'] = (df['days_since_last_funding'] <= 365).astype(int)  # Funded in last year\n",
    "df['recently_milestone'] = (df['days_since_last_milestone'] <= 365).astype(int)  # Milestone in last year\n",
    "df['recently_updated'] = (df['days_since_last_update'] <= 90).astype(int)  # Updated in last 3 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b98c49e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall business maturity score\n",
    "df['business_maturity_score'] = (\n",
    "    0.2 * df['digital_presence_score'] +\n",
    "    0.2 * df['achievement_score'] +\n",
    "    0.2 * (df['recently_funded'] + df['recently_milestone'] + df['recently_updated']) / 3 +\n",
    "    0.2 * df['text_sophistication'] +\n",
    "    0.2 * df['investment_activity_score']\n",
    ")\n",
    "\n",
    "# Ecosystem engagement (how connected/active the company is)\n",
    "df['ecosystem_engagement'] = (\n",
    "    0.3 * (df['network_connectivity'] / (df['network_connectivity'].max() + 1)) +\n",
    "    0.2 * df['has_twitter'] +\n",
    "    0.3 * (df['content_richness'] / 3)\n",
    ")\n",
    "\n",
    "# Strategic positioning (investor appeal factors)\n",
    "df['strategic_positioning'] = (\n",
    "    0.25 * df['funding_vs_industry_avg'] +\n",
    "    0.25 * df['digital_presence_score'] +\n",
    "    0.25 * df['achievement_score'] +\n",
    "    0.25 * df['ecosystem_engagement']\n",
    ") \n",
    "\n",
    "# Operational sophistication (professional setup indicators)\n",
    "df['operational_sophistication'] = (\n",
    "    0.3 * df['has_domain'] +\n",
    "    0.2 * df['has_twitter'] +\n",
    "    0.3 * (df['content_richness'] / 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ce4f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../processed_data/companies_feature_engineering.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0465979",
   "metadata": {},
   "source": [
    "# 1. Under-Capitalized Startup Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b072369",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1: Under-Capitalization Identification & Core Features\n",
    "\n",
    "```\n",
    "ALGORITHM: Under-Cap Population Feature Engineering\n",
    "1. Load funding percentiles from data_cleaning phase:\n",
    "   - Use 2% threshold established in previous notebook\n",
    "   - Validate under_capitalized flag exists and is accurate\n",
    "   - Create under-cap specific feature derivatives\n",
    "\n",
    "2. Core Under-Cap Features:\n",
    "   - undercap_survival_months = company_age_years * 12 (survival with minimal funding)\n",
    "   - bootstrap_efficiency = milestones / (funding_total_usd + 1) (achievements per dollar)\n",
    "   - capital_efficiency = revenue_proxy / (funding_total_usd + 1) (value creation per dollar)\n",
    "   - undercap_longevity_score = survival_months / industry_avg_survival\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- under_capitalized flag validated: \"X,XXX companies (X.X%)\"\n",
    "- Bootstrap efficiency distribution analysis\n",
    "- Capital efficiency metrics by industry\n",
    "- Survival analysis features for under-cap population\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d922cbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total under-capitalized companies: 169,216 (86.1%)\n",
      "Bootstrap efficiency (mean): 0.43\n",
      "Capital efficiency: N/A (no revenue_proxy available)\n",
      "Undercap longevity score (mean): 1.00\n"
     ]
    }
   ],
   "source": [
    "# Ensure under_capitalized flag exists\n",
    "if 'under_capitalized' not in df.columns:\n",
    "    df['under_capitalized'] = 0  # default to 0 if missing\n",
    "\n",
    "# Step 1: Under-Cap Core Features\n",
    "df['undercap_survival_months'] = df['company_age_years'] * 12\n",
    "df['bootstrap_efficiency'] = df['milestones'].fillna(0) / (df['funding_total_usd'].fillna(0) + 1)\n",
    "\n",
    "# Capital efficiency: handle missing revenue_proxy\n",
    "if 'revenue_proxy' in df.columns:\n",
    "    df['capital_efficiency'] = df['revenue_proxy'] / (df['funding_total_usd'] + 1)\n",
    "else:\n",
    "    df['capital_efficiency'] = np.nan\n",
    "\n",
    "# Industry average survival proxy (or global if unavailable)\n",
    "if 'category_code' in df.columns:\n",
    "    industry_avg_survival = df.groupby('category_code')['company_age_years'].transform('mean')\n",
    "else:\n",
    "    industry_avg_survival = df['company_age_years'].mean()\n",
    "\n",
    "df['undercap_longevity_score'] = df['undercap_survival_months'] / (industry_avg_survival * 12 + 1e-6)\n",
    "\n",
    "# Step 2: Print summary stats\n",
    "total_undercap = df['under_capitalized'].sum()\n",
    "pct_undercap = df['under_capitalized'].mean() * 100\n",
    "\n",
    "print(f\"Total under-capitalized companies: {total_undercap:,} ({pct_undercap:.1f}%)\")\n",
    "print(f\"Bootstrap efficiency (mean): {df['bootstrap_efficiency'].mean():.2f}\")\n",
    "if df['capital_efficiency'].notna().any():\n",
    "    print(f\"Capital efficiency (mean): {df['capital_efficiency'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"Capital efficiency: N/A (no revenue_proxy available)\")\n",
    "print(f\"Undercap longevity score (mean): {df['undercap_longevity_score'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6770c17",
   "metadata": {},
   "source": [
    "## Step 2: Under-Cap Peer Comparison Features\n",
    "\n",
    "```\n",
    "ALGORITHM: Under-Cap Comparative Analysis Features\n",
    "1. Create under-cap peer groups:\n",
    "   - Group by [category_code, founding_era] for under-cap companies\n",
    "   - Calculate under-cap specific benchmarks and percentiles\n",
    "   - Generate peer comparison metrics\n",
    "\n",
    "2. Under-Cap Peer Features:\n",
    "   - undercap_peer_success_rate = success_rate_in_undercap_peer_group\n",
    "   - undercap_peer_survival_comparison = survival_vs_undercap_peers\n",
    "   - undercap_sector_density = undercap_companies_in_sector / total_sector_companies\n",
    "   - undercap_geographic_density = undercap_companies_in_region / total_region_companies\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Peer group success rate benchmarks by sector\n",
    "- Under-cap concentration metrics by geography/industry\n",
    "- Relative positioning within under-cap ecosystem\n",
    "- Competitive analysis within funding-constrained environment\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da61224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total under-cap companies: 169,216\n",
      "Average under-cap peer success rate: 0.24%\n",
      "Average under-cap peer survival (years): 15.67\n",
      "Average under-cap bootstrap efficiency: 0.49\n",
      "Average under-cap sector density: 86.10%\n",
      "Average under-cap geographic density: 86.10%\n"
     ]
    }
   ],
   "source": [
    "# Create under-cap peer dataset\n",
    "undercap_df = df[df['under_capitalized'] == 1].copy()\n",
    "\n",
    "# Determine grouping columns\n",
    "merge_cols = [c for c in ['category_code', 'founding_era'] if c in df.columns]\n",
    "\n",
    "# Initialize peer columns\n",
    "peer_cols = [\n",
    "    'undercap_peer_count', \n",
    "    'undercap_peer_success_rate',\n",
    "    'undercap_peer_avg_survival', \n",
    "    'undercap_peer_median_milestones',\n",
    "    'undercap_peer_avg_efficiency',\n",
    "    'undercap_sector_density',\n",
    "    'undercap_geographic_density'\n",
    "]\n",
    "\n",
    "# Drop existing peer columns to avoid merge conflicts\n",
    "df = df.drop(columns=[c for c in peer_cols if c in df.columns], errors='ignore')\n",
    "\n",
    "# Compute peer stats if possible\n",
    "if len(merge_cols) > 0 and len(undercap_df) > 0:\n",
    "    # Ensure 'id' exists, else use a surrogate\n",
    "    id_col = 'id' if 'id' in df.columns else df.index.name if df.index.name else df.index\n",
    "    undercap_peer_stats = (\n",
    "        undercap_df.groupby(merge_cols)\n",
    "        .agg(\n",
    "            undercap_peer_count=(id_col, 'count'),\n",
    "            undercap_peer_success_rate=('failure_risk', lambda x: 1 - x.mean() if len(x) > 0 else np.nan),\n",
    "            undercap_peer_avg_survival=('company_age_years', 'mean'),\n",
    "            undercap_peer_median_milestones=('milestones', 'median'),\n",
    "            undercap_peer_avg_efficiency=('bootstrap_efficiency', 'mean')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    df = df.merge(undercap_peer_stats, on=merge_cols, how='left')\n",
    "\n",
    "# Compute sector and geographic density\n",
    "if 'category_code' in df.columns:\n",
    "    df['undercap_sector_density'] = df.groupby('category_code')['under_capitalized'].transform('mean')\n",
    "else:\n",
    "    df['undercap_sector_density'] = np.nan\n",
    "\n",
    "if 'country_code' in df.columns:\n",
    "    df['undercap_geographic_density'] = df.groupby('country_code')['under_capitalized'].transform('mean')\n",
    "else:\n",
    "    df['undercap_geographic_density'] = np.nan\n",
    "\n",
    "# Fill missing values with global averages\n",
    "global_success = 1 - undercap_df['failure_risk'].mean() if len(undercap_df) > 0 else 0\n",
    "global_survival = undercap_df['company_age_years'].mean() if len(undercap_df) > 0 else 0\n",
    "global_efficiency = undercap_df['bootstrap_efficiency'].mean() if len(undercap_df) > 0 else 0\n",
    "global_milestones = undercap_df['milestones'].median() if len(undercap_df) > 0 else 0\n",
    "\n",
    "df['undercap_peer_success_rate'] = df.get('undercap_peer_success_rate', np.nan).fillna(global_success)\n",
    "df['undercap_peer_avg_survival'] = df.get('undercap_peer_avg_survival', np.nan).fillna(global_survival)\n",
    "df['undercap_peer_count'] = df.get('undercap_peer_count', 0).fillna(0)\n",
    "df['undercap_peer_median_milestones'] = df.get('undercap_peer_median_milestones', np.nan).fillna(global_milestones)\n",
    "df['undercap_peer_avg_efficiency'] = df.get('undercap_peer_avg_efficiency', np.nan).fillna(global_efficiency)\n",
    "df['undercap_sector_density'] = df['undercap_sector_density'].fillna(0)\n",
    "df['undercap_geographic_density'] = df['undercap_geographic_density'].fillna(0)\n",
    "\n",
    "# Comparative feature: survival vs undercap peers\n",
    "df['undercap_peer_survival_comparison'] = df['company_age_years'] - df['undercap_peer_avg_survival']\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total under-cap companies: {len(undercap_df):,}\")\n",
    "print(f\"Average under-cap peer success rate: {df['undercap_peer_success_rate'].mean():.2%}\")\n",
    "print(f\"Average under-cap peer survival (years): {df['undercap_peer_avg_survival'].mean():.2f}\")\n",
    "print(f\"Average under-cap bootstrap efficiency: {df['undercap_peer_avg_efficiency'].mean():.2f}\")\n",
    "print(f\"Average under-cap sector density: {df['undercap_sector_density'].mean():.2%}\")\n",
    "print(f\"Average under-cap geographic density: {df['undercap_geographic_density'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802a8a8",
   "metadata": {},
   "source": [
    "## Step 3: Bootstrap Success Indicators\n",
    "\n",
    "```\n",
    "ALGORITHM: Zero/Minimal Funding Success Features\n",
    "1. Identify bootstrap success patterns:\n",
    "   - Companies with $0 funding but high milestones\n",
    "   - Long survival (3+ years) with minimal funding\n",
    "   - Growth indicators without traditional VC funding\n",
    "\n",
    "2. Bootstrap Features:\n",
    "   - zero_funding_survivor = (funding == 0) & (age > 3 years)\n",
    "   - bootstrap_milestone_velocity = milestones / months_without_funding\n",
    "   - organic_growth_indicator = milestone_growth_rate without funding_events\n",
    "   - self_sustaining_score = operational_longevity without external_capital\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Bootstrap success identification: \"X companies survived 3+ years with $0 funding\"\n",
    "- Milestone velocity for unfunded companies\n",
    "- Organic growth pattern analysis\n",
    "- Self-sustainability scoring framework\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c4d26d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies survived 3+ years with $0 funding: 0\n",
      "Under-cap long survivors (5+ years): 169,216\n",
      "High milestone under-cap companies (>= 75th percentile): 76,693\n",
      "Average bootstrap milestone velocity: 0.00 per month\n",
      "Average organic growth indicator: 0.04\n",
      "Companies showing growth without VC: 3,276\n",
      "Average self-sustaining score: 0.34\n",
      "Sustainability tiers distribution:\n",
      "  Low: 50,188\n",
      "  Medium: 136,398\n",
      "  High: 9,651\n",
      "  Very High: 293\n"
     ]
    }
   ],
   "source": [
    "# Zero funding survivors (3+ years)\n",
    "df['zero_funding_survivor'] = ((df['funding_total_usd'] == 0) & (df['company_age_years'] >= 3)).astype(int)\n",
    "\n",
    "# Minimal funding long survivors (under-cap + 5+ years)\n",
    "df['minimal_funding_long_survivor'] = ((df['under_capitalized'] == 1) & (df['company_age_years'] >= 5)).astype(int)\n",
    "\n",
    "# High milestones among minimal funding (75th percentile)\n",
    "milestone_75th = df['milestones'].quantile(0.75)\n",
    "df['high_milestone_minimal_funding'] = ((df['under_capitalized'] == 1) & (df['milestones'] >= milestone_75th)).astype(int)\n",
    "\n",
    "# Months to first funding (use survival months for missing)\n",
    "if 'time_to_first_funding_days' in df.columns:\n",
    "    df['months_to_first_funding'] = df['time_to_first_funding_days'] / 30.44\n",
    "else:\n",
    "    df['months_to_first_funding'] = np.nan\n",
    "df['months_to_first_funding'] = df['months_to_first_funding'].fillna(df.get('undercap_survival_months', 36))  # default 36 months\n",
    "\n",
    "# Milestone velocity per month\n",
    "df['bootstrap_milestone_velocity'] = df['milestones'] / (df['months_to_first_funding'] + 1)\n",
    "\n",
    "# Organic growth indicator (milestones per year without recent funding)\n",
    "if 'recently_funded' in df.columns and 'milestones_per_year' in df.columns:\n",
    "    df['organic_growth_indicator'] = np.where(df['recently_funded'] == 0, df['milestones_per_year'], 0)\n",
    "else:\n",
    "    df['organic_growth_indicator'] = 0\n",
    "\n",
    "# Growth without VC (minimal funding but above median milestones)\n",
    "milestone_median = df['milestones'].median()\n",
    "funding_25th = df['funding_total_usd'].quantile(0.25)\n",
    "df['growth_without_vc'] = ((df['funding_total_usd'] < funding_25th) & (df['milestones'] > milestone_median)).astype(int)\n",
    "\n",
    "# Self-sustaining score (composite metric)\n",
    "df['self_sustaining_score'] = (\n",
    "    0.3 * (df.get('undercap_survival_months', 0) / (df.get('undercap_survival_months', 36).max() + 1)) +\n",
    "    0.3 * np.clip(df.get('bootstrap_efficiency', 0) / df.get('bootstrap_efficiency', pd.Series([1])).quantile(0.99), 0, 1) +\n",
    "    0.2 * df['zero_funding_survivor'] +\n",
    "    0.2 * np.clip(df.get('undercap_longevity_score', 0), 0, 1)\n",
    ")\n",
    "# Clip to 0–1\n",
    "df['self_sustaining_score'] = np.clip(df['self_sustaining_score'], 0, 1)\n",
    "\n",
    "# Sustainability tiers\n",
    "df['sustainability_tier'] = pd.cut(\n",
    "    df['self_sustaining_score'],\n",
    "    bins=[0, 0.25, 0.5, 0.75, 1.0],\n",
    "    labels=['Low', 'Medium', 'High', 'Very High']\n",
    ")\n",
    "\n",
    "# Print summary outputs\n",
    "print(f\"Companies survived 3+ years with $0 funding: {df['zero_funding_survivor'].sum():,}\")\n",
    "print(f\"Under-cap long survivors (5+ years): {df['minimal_funding_long_survivor'].sum():,}\")\n",
    "print(f\"High milestone under-cap companies (>= 75th percentile): {df['high_milestone_minimal_funding'].sum():,}\")\n",
    "print(f\"Average bootstrap milestone velocity: {df['bootstrap_milestone_velocity'].mean():.2f} per month\")\n",
    "print(f\"Average organic growth indicator: {df['organic_growth_indicator'].mean():.2f}\")\n",
    "print(f\"Companies showing growth without VC: {df['growth_without_vc'].sum():,}\")\n",
    "print(f\"Average self-sustaining score: {df['self_sustaining_score'].mean():.2f}\")\n",
    "\n",
    "tier_counts = df['sustainability_tier'].value_counts().reindex(['Low', 'Medium', 'High', 'Very High'], fill_value=0)\n",
    "print(\"Sustainability tiers distribution:\")\n",
    "for tier, count in tier_counts.items():\n",
    "    print(f\"  {tier}: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619689b2",
   "metadata": {},
   "source": [
    "# 2. Founder Team Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be409caf",
   "metadata": {},
   "source": [
    "## Step 1: Team Size Extraction from Available Data\n",
    "\n",
    "```\n",
    "ALGORITHM: Founder Team Feature Engineering\n",
    "1. Parse relationships column for team insights:\n",
    "   - Extract founder, co-founder, employee counts from relationships string\n",
    "   - Parse created_by field for founding team information\n",
    "   - Use text analysis to identify team size indicators\n",
    "\n",
    "2. Team Size Features:\n",
    "   - founder_count = extracted_founder_count from relationships\n",
    "   - cofounder_count = extracted_cofounder_count from relationships  \n",
    "   - team_size_proxy = founder_count + cofounder_count + key_employees\n",
    "   - solo_founder = (founder_count == 1) & (cofounder_count == 0)\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Team size distribution: \"Solo: X%, Small team (2-3): X%, Large team (4+): X%\"\n",
    "- Founder team extraction success rate\n",
    "- Team composition analysis by industry/success rate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb274b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total companies: 196,530\n",
      "Total solo founder companies: 0\n",
      "Average number of founders: 0.00\n",
      "Average number of cofounders: 0.00\n",
      "Average team size proxy: 0.00\n",
      "\n",
      "Team size category distribution:\n",
      "  Solo: 0\n",
      "  Small (2-3): 0\n",
      "  Large (4+): 0\n"
     ]
    }
   ],
   "source": [
    "# Ensure relationships column exists\n",
    "if 'relationships' not in df.columns:\n",
    "    df['relationships'] = None\n",
    "\n",
    "# Initialize founder and cofounder counts\n",
    "df['founder_count'] = 0\n",
    "df['cofounder_count'] = 0\n",
    "\n",
    "# Extract founder/cofounder counts\n",
    "def extract_founder_counts(rel):\n",
    "    founder = 0\n",
    "    cofounder = 0\n",
    "    if isinstance(rel, list):\n",
    "        for r in rel:\n",
    "            role = r.get('title', '').lower() if isinstance(r, dict) else ''\n",
    "            if 'founder' in role and 'co' not in role:\n",
    "                founder += 1\n",
    "            elif 'co-founder' in role or 'cofounder' in role:\n",
    "                cofounder += 1\n",
    "    return pd.Series([founder, cofounder])\n",
    "\n",
    "df[['founder_count', 'cofounder_count']] = df['relationships'].apply(extract_founder_counts)\n",
    "\n",
    "# Employee count handling\n",
    "if 'employee_count' in df.columns:\n",
    "    df['employee_count'] = df['employee_count'].fillna(0).clip(lower=0)\n",
    "    df['team_size_proxy'] = df['founder_count'] + df['cofounder_count'] + df['employee_count']\n",
    "else:\n",
    "    df['team_size_proxy'] = df['founder_count'] + df['cofounder_count']\n",
    "\n",
    "# Solo founder flag\n",
    "df['solo_founder'] = ((df['founder_count'] == 1) & (df['cofounder_count'] == 0)).astype(int)\n",
    "\n",
    "# Team size categories\n",
    "df['team_size_category'] = pd.cut(\n",
    "    df['team_size_proxy'],\n",
    "    bins=[0, 1, 3, 1000],\n",
    "    labels=['Solo', 'Small (2-3)', 'Large (4+)']\n",
    ")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"Total companies: {len(df):,}\")\n",
    "print(f\"Total solo founder companies: {df['solo_founder'].sum():,}\")\n",
    "print(f\"Average number of founders: {df['founder_count'].mean():.2f}\")\n",
    "print(f\"Average number of cofounders: {df['cofounder_count'].mean():.2f}\")\n",
    "print(f\"Average team size proxy: {df['team_size_proxy'].mean():.2f}\")\n",
    "\n",
    "print(\"\\nTeam size category distribution:\")\n",
    "team_size_counts = df['team_size_category'].value_counts().reindex(['Solo', 'Small (2-3)', 'Large (4+)'], fill_value=0)\n",
    "for category, count in team_size_counts.items():\n",
    "    print(f\"  {category}: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e49dc9",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Team-Based Success Analysis\n",
    "\n",
    "```\n",
    "ALGORITHM: Team Dynamics Impact Features\n",
    "1. Analyze team size impact on success:\n",
    "   - Success rates by team size categories\n",
    "   - Funding patterns by team composition\n",
    "   - Industry preferences for team sizes\n",
    "\n",
    "2. Team Impact Features:\n",
    "   - team_size_success_correlation = success_rate_for_team_size_category\n",
    "   - team_funding_advantage = funding_vs_avg by team_size\n",
    "   - team_survival_benefit = survival_rate by team_composition\n",
    "   - optimal_team_size_flag = team_size in optimal_range_for_industry\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Team size success correlation by industry\n",
    "- Optimal team size recommendations by sector\n",
    "- Team composition impact on funding acquisition\n",
    "- Solo founder success rate analysis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "597b6ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total industries analyzed: 42\n",
      "Optimal team size category per industry:\n",
      "   category_code optimal_team_size_category\n",
      "     advertising                        nan\n",
      "       analytics                        nan\n",
      "      automotive                        nan\n",
      "         biotech                        nan\n",
      "       cleantech                        nan\n",
      "      consulting                        nan\n",
      "          design                        nan\n",
      "       ecommerce                        nan\n",
      "       education                        nan\n",
      "      enterprise                        nan\n",
      "         fashion                        nan\n",
      "         finance                        nan\n",
      "     games_video                        nan\n",
      "      government                        nan\n",
      "        hardware                        nan\n",
      "          health                        nan\n",
      "     hospitality                        nan\n",
      "           legal                        nan\n",
      "           local                        nan\n",
      "   manufacturing                        nan\n",
      "         medical                        nan\n",
      "       messaging                        nan\n",
      "          mobile                        nan\n",
      "           music                        nan\n",
      "        nanotech                        nan\n",
      " network_hosting                        nan\n",
      "            news                        nan\n",
      "       nonprofit                        nan\n",
      "           other                        nan\n",
      "            pets                        nan\n",
      "     photo_video                        nan\n",
      "public_relations                        nan\n",
      "     real_estate                        nan\n",
      "          search                        nan\n",
      "        security                        nan\n",
      "   semiconductor                        nan\n",
      "          social                        nan\n",
      "        software                        nan\n",
      "          sports                        nan\n",
      "  transportation                        nan\n",
      "          travel                        nan\n",
      "             web                        nan\n",
      "\n",
      "Companies matching optimal team size: 196,530 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'team_size_category' exists\n",
    "if 'team_size_category' not in df.columns:\n",
    "    df['team_size_category'] = np.nan\n",
    "\n",
    "# Convert to string for consistent comparison\n",
    "df['team_size_category'] = df['team_size_category'].astype(str)\n",
    "\n",
    "# Compute optimal team size per industry\n",
    "if 'category_code' in df.columns:\n",
    "    optimal_team_size = (\n",
    "        df.groupby(['category_code', 'team_size_category'], observed=True)\n",
    "        .agg(success_rate=('failure_risk', lambda x: 1 - x.mean() if len(x.dropna()) > 0 else np.nan))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    if not optimal_team_size.empty:\n",
    "        # Get the team_size_category with max success_rate per industry\n",
    "        optimal_team_size_idx = optimal_team_size.groupby('category_code')['success_rate'].idxmax()\n",
    "        optimal_team_df = optimal_team_size.loc[optimal_team_size_idx, ['category_code', 'team_size_category']].copy()\n",
    "        optimal_team_df = optimal_team_df.rename(columns={'team_size_category': 'optimal_team_size_category'})\n",
    "        df = df.merge(optimal_team_df, on='category_code', how='left')\n",
    "    else:\n",
    "        df['optimal_team_size_category'] = 'None'\n",
    "else:\n",
    "    df['optimal_team_size_category'] = 'None'\n",
    "\n",
    "# Ensure optimal team size column is string\n",
    "df['optimal_team_size_category'] = df['optimal_team_size_category'].astype(str)\n",
    "\n",
    "# Create flag\n",
    "df['optimal_team_size_flag'] = (df['team_size_category'] == df['optimal_team_size_category']).astype(int)\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"Total industries analyzed: {df['category_code'].nunique():,}\")\n",
    "print(\"Optimal team size category per industry:\")\n",
    "print(df[['category_code', 'optimal_team_size_category']].drop_duplicates().sort_values('category_code').to_string(index=False))\n",
    "print(f\"\\nCompanies matching optimal team size: {df['optimal_team_size_flag'].sum():,} ({df['optimal_team_size_flag'].mean():.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6f789d",
   "metadata": {},
   "source": [
    "## Step 3: Team Quality Proxy Features \n",
    "\n",
    "```\n",
    "ALGORITHM: Team Experience and Quality Indicators\n",
    "1. Create team quality proxies from available data:\n",
    "   - Network connectivity as team experience indicator\n",
    "   - Digital sophistication as team professionalism\n",
    "   - Content quality as team communication skills\n",
    "\n",
    "2. Team Quality Features:\n",
    "   - team_network_strength = relationships_count / team_size_proxy\n",
    "   - team_digital_maturity = digital_presence_score / team_size_proxy\n",
    "   - team_communication_quality = text_sophistication / team_size_proxy\n",
    "   - founding_team_experience = years_experience_proxy from network_data\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Team quality scoring methodology\n",
    "- Experience proxy validation metrics\n",
    "- Team competency assessment framework\n",
    "- Founding team strength indicators\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "074b1212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average team network strength: 1.88\n",
      "Average team digital maturity: 0.87\n",
      "Average team communication quality: 0.13\n",
      "Average founding team experience (years): 0.00\n",
      "Average composite team score: 0.53\n"
     ]
    }
   ],
   "source": [
    "# Ensure necessary columns exist\n",
    "for col in ['relationships_count', 'team_size_proxy', 'digital_presence_score', \n",
    "            'text_sophistication', 'years_experience_proxy']:\n",
    "    if col not in df.columns:\n",
    "        df[col] = 0  # fallback default\n",
    "\n",
    "# Compute team quality proxies\n",
    "df['team_network_strength'] = df['relationships_count'] / df['team_size_proxy'].replace(0, 1)\n",
    "df['team_digital_maturity'] = df['digital_presence_score'] / df['team_size_proxy'].replace(0, 1)\n",
    "df['team_communication_quality'] = df['text_sophistication'] / df['team_size_proxy'].replace(0, 1)\n",
    "df['founding_team_experience'] = df['years_experience_proxy']\n",
    "\n",
    "# Fill any remaining NaNs with 0\n",
    "team_cols = ['team_network_strength', 'team_digital_maturity', \n",
    "             'team_communication_quality', 'founding_team_experience']\n",
    "df[team_cols] = df[team_cols].fillna(0)\n",
    "\n",
    "# Composite team score\n",
    "experience_max = df['founding_team_experience'].max() if df['founding_team_experience'].max() > 0 else 1\n",
    "df['team_composite_score'] = (\n",
    "    0.25 * df['team_network_strength'] +\n",
    "    0.25 * df['team_digital_maturity'] +\n",
    "    0.25 * df['team_communication_quality'] +\n",
    "    0.25 * (df['founding_team_experience'] / experience_max)\n",
    ")\n",
    "\n",
    "# Optional: clip composite score between 0 and 1\n",
    "df['team_composite_score'] = df['team_composite_score'].clip(0, 1)\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Average team network strength: {df['team_network_strength'].mean():.2f}\")\n",
    "print(f\"Average team digital maturity: {df['team_digital_maturity'].mean():.2f}\")\n",
    "print(f\"Average team communication quality: {df['team_communication_quality'].mean():.2f}\")\n",
    "print(f\"Average founding team experience (years): {df['founding_team_experience'].mean():.2f}\")\n",
    "print(f\"Average composite team score: {df['team_composite_score'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4fa3f2",
   "metadata": {},
   "source": [
    "# 3. Stage Transition Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6dad34",
   "metadata": {},
   "source": [
    "## Step 1: Dynamic Stage Progression Analysis\n",
    "\n",
    "```\n",
    "ALGORITHM: Stage Transition Feature Engineering\n",
    "1. Enhance existing funding_stage with transition dynamics:\n",
    "   - Calculate stage progression velocity (stages_per_year)\n",
    "   - Identify stage transition patterns and timing\n",
    "   - Measure time spent in each funding stage\n",
    "\n",
    "2. Stage Transition Features:\n",
    "   - funding_stage_numeric = map stages to numeric scale (0-6)\n",
    "   - stage_progression_rate = funding_stage_numeric / (company_age_years + 1)\n",
    "   - time_in_current_stage = estimated_time_in_current_funding_stage\n",
    "   - stage_transition_velocity = stages_progressed / years_active\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Stage progression rate distribution\n",
    "- Average time spent in each funding stage\n",
    "- Stage transition success patterns\n",
    "- Velocity benchmarks by industry\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "254f8871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unmapped funding stages: ['Growth' 'Exit (Acquired)' 'Late' 'Early' 'Exit (IPO)']\n",
      "Valid companies with numeric stage: 19,995\n",
      "Average funding stage numeric: 0.47\n",
      "Average stage progression rate: 0.03 stages/year\n",
      "Median stage progression rate: 0.00 stages/year\n",
      "Average time in current stage (months): 174.65\n",
      "Median time in current stage (months): 166.00\n",
      "Average stage transition velocity: 0.03 stages/year\n"
     ]
    }
   ],
   "source": [
    "# Funding stage mapping (numeric scale 0-6)\n",
    "funding_stage_mapping = {\n",
    "    'pre-seed': 0,\n",
    "    'seed': 1,\n",
    "    'angel': 2,\n",
    "    'series_a': 3,\n",
    "    'series_b': 4,\n",
    "    'series_c': 5,\n",
    "    'series_d+': 5,\n",
    "    'ipo': 6,\n",
    "    'acquired': 6,\n",
    "    'closed': 0\n",
    "}\n",
    "\n",
    "# Ensure funding_stage column exists\n",
    "if 'funding_stage' not in df.columns:\n",
    "    df['funding_stage'] = np.nan\n",
    "\n",
    "df['funding_stage_clean'] = df['funding_stage'].astype(str).str.strip().str.lower()\n",
    "df['funding_stage_numeric'] = df['funding_stage_clean'].map(funding_stage_mapping)\n",
    "\n",
    "# Inspect unmapped stages\n",
    "unmapped_stages = df[df['funding_stage_numeric'].isna()]['funding_stage'].unique()\n",
    "if len(unmapped_stages) > 0:\n",
    "    print(\"Warning: Unmapped funding stages:\", unmapped_stages)\n",
    "\n",
    "# Safe company age to avoid division by zero\n",
    "df['company_age_years_safe'] = df['company_age_years'].replace(0, np.nan)\n",
    "\n",
    "# Stage progression metrics\n",
    "df['stage_progression_rate'] = df['funding_stage_numeric'] / df['company_age_years_safe']\n",
    "\n",
    "# Stage transition velocity: can be refined if previous stage data exists\n",
    "df['stage_transition_velocity'] = df['funding_stage_numeric'] / df['company_age_years_safe']\n",
    "\n",
    "# Time in current stage (months)\n",
    "if 'months_since_last_funding' in df.columns:\n",
    "    df['time_in_current_stage'] = df['months_since_last_funding']\n",
    "elif 'last_funding_at' in df.columns and 'current_date' not in locals():\n",
    "    current_date = pd.Timestamp.now()\n",
    "    df['time_in_current_stage'] = ((current_date - df['last_funding_at']).dt.days / 30.44).fillna(np.nan)\n",
    "else:\n",
    "    df['time_in_current_stage'] = np.nan\n",
    "\n",
    "# Summary statistics\n",
    "valid_numeric = df['funding_stage_numeric'].notna().sum()\n",
    "print(f\"Valid companies with numeric stage: {valid_numeric:,}\")\n",
    "print(f\"Average funding stage numeric: {df['funding_stage_numeric'].mean(skipna=True):.2f}\")\n",
    "print(f\"Average stage progression rate: {df['stage_progression_rate'].mean(skipna=True):.2f} stages/year\")\n",
    "print(f\"Median stage progression rate: {df['stage_progression_rate'].median(skipna=True):.2f} stages/year\")\n",
    "print(f\"Average time in current stage (months): {df['time_in_current_stage'].mean(skipna=True):.2f}\")\n",
    "print(f\"Median time in current stage (months): {df['time_in_current_stage'].median(skipna=True):.2f}\")\n",
    "print(f\"Average stage transition velocity: {df['stage_transition_velocity'].mean(skipna=True):.2f} stages/year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b714370",
   "metadata": {},
   "source": [
    "## Step 2: Stage Transition Risk Indicators\n",
    "\n",
    "```\n",
    "ALGORITHM: Stage Stagnation and Progression Analysis\n",
    "1. Identify stage transition risk patterns:\n",
    "   - Companies stuck in early stages too long\n",
    "   - Rapid progression indicating hot startups\n",
    "   - Stage regression indicators (funding decline)\n",
    "\n",
    "2. Stage Risk Features:\n",
    "   - stuck_in_early_stage = (stage <= Seed) & (age > 5 years)\n",
    "   - rapid_progression = (stage >= Growth) & (age <= 3 years)\n",
    "   - stage_appropriate_age = age_matches_expected_stage_timeline\n",
    "   - progression_risk_score = deviation_from_normal_progression_pattern\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Early stage stagnation identification: \"X companies stuck in seed stage 5+ years\"\n",
    "- Rapid progression patterns: \"X companies reached growth stage in <3 years\"\n",
    "- Stage-age alignment analysis\n",
    "- Progression risk scoring distribution\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b44286e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies stuck in early stage (>5 years): 19,995\n",
      "Companies with rapid progression (Growth stage <=3 years): 0\n",
      "Average progression risk score: 19.68\n",
      "Companies with stage-appropriate age: 0\n"
     ]
    }
   ],
   "source": [
    "# Ensure funding_stage_numeric exists\n",
    "if 'funding_stage_numeric' not in df.columns:\n",
    "    raise ValueError(\"Column 'funding_stage_numeric' must exist. Run Step 1 first.\")\n",
    "\n",
    "# Safe company age to avoid division by zero\n",
    "df['company_age_years_safe'] = df['company_age_years'].replace(0, np.nan)\n",
    "\n",
    "# Define stage thresholds\n",
    "early_stage_threshold = 1  # Seed/Angel or lower\n",
    "growth_stage_threshold = 2  # Series A or above\n",
    "\n",
    "# 1. Stuck in early stage (>5 years in Seed/Angel)\n",
    "df['stuck_in_early_stage'] = ((df['funding_stage_numeric'] <= early_stage_threshold) &\n",
    "                              (df['company_age_years_safe'] > 5)).astype(int)\n",
    "\n",
    "# 2. Rapid progression (Growth stage reached <=3 years)\n",
    "df['rapid_progression'] = ((df['funding_stage_numeric'] >= growth_stage_threshold) &\n",
    "                           (df['company_age_years_safe'] <= 3)).astype(int)\n",
    "\n",
    "# 3. Stage-appropriate age (heuristic)\n",
    "expected_age_per_stage = {0: 0.5, 1: 2, 2: 3, 3: 5, 4: 6, 5: 8, 6: 10}  # Adjusted minimums for early stages\n",
    "df['expected_age_for_stage'] = df['funding_stage_numeric'].map(expected_age_per_stage)\n",
    "\n",
    "# Flag if company age is within 50-150% of expected stage age\n",
    "df['stage_appropriate_age'] = ((df['company_age_years_safe'] >= 0.5 * df['expected_age_for_stage']) &\n",
    "                               (df['company_age_years_safe'] <= 1.5 * df['expected_age_for_stage'])).astype(int)\n",
    "\n",
    "# 4. Progression risk score: deviation from expected age\n",
    "df['progression_risk_score'] = abs(df['company_age_years_safe'] - df['expected_age_for_stage']) / \\\n",
    "                               df['expected_age_for_stage'].replace(0, np.nan)\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Companies stuck in early stage (>5 years): {df['stuck_in_early_stage'].sum():,}\")\n",
    "print(f\"Companies with rapid progression (Growth stage <=3 years): {df['rapid_progression'].sum():,}\")\n",
    "print(f\"Average progression risk score: {df['progression_risk_score'].mean(skipna=True):.2f}\")\n",
    "print(f\"Companies with stage-appropriate age: {df['stage_appropriate_age'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0700ab7",
   "metadata": {},
   "source": [
    "## Step 3: Industry-Specific Stage Benchmarks\n",
    "\n",
    "```\n",
    "ALGORITHM: Industry Stage Transition Benchmarks\n",
    "1. Create industry-specific stage progression norms:\n",
    "   - Calculate industry average progression timelines\n",
    "   - Identify sector-specific stage transition patterns\n",
    "   - Generate industry stage transition benchmarks\n",
    "\n",
    "2. Industry Stage Features:\n",
    "   - industry_stage_norm = normal_stage_for_age_in_industry\n",
    "   - stage_vs_industry_expectation = current_stage - expected_stage_for_industry\n",
    "   - industry_progression_percentile = percentile_ranking_in_industry_progression\n",
    "   - sector_stage_advantage = stage_advancement_vs_industry_avg\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Industry-specific stage progression timelines\n",
    "- Sector stage transition benchmark tables\n",
    "- Stage advancement percentile rankings\n",
    "- Industry progression advantage analysis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0809ea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample industry stage benchmarking metrics:\n",
      "  category_code  funding_stage_numeric  industry_avg_stage  stage_vs_industry_expectation  industry_progression_percentile  sector_stage_advantage\n",
      "            web                    NaN            0.304680                            NaN                              NaN                     NaN\n",
      "    games_video                    NaN            0.398089                            NaN                              NaN                     NaN\n",
      "    games_video                    NaN            0.398089                            NaN                              NaN                     NaN\n",
      "network_hosting                    NaN            0.474510                            NaN                              NaN                     NaN\n",
      "    games_video                    NaN            0.398089                            NaN                              NaN                     NaN\n",
      "    advertising                    NaN            0.464043                            NaN                              NaN                     NaN\n",
      "      cleantech                    NaN            0.593750                            NaN                              NaN                     NaN\n",
      "          other                    NaN            0.440094                            NaN                              NaN                     NaN\n",
      "    advertising                    NaN            0.464043                            NaN                              NaN                     NaN\n",
      "     enterprise                    NaN            0.545670                            NaN                              NaN                     NaN\n",
      "\n",
      "Average stage vs industry expectation: -0.00\n",
      "Average industry progression percentile: 0.50\n",
      "Average sector stage advantage: -0.00\n"
     ]
    }
   ],
   "source": [
    "# Ensure necessary columns exist\n",
    "required_cols = ['category_code', 'funding_stage_numeric', 'company_age_years_safe']\n",
    "missing_cols = [c for c in required_cols if c not in df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing required columns for industry benchmarking: {missing_cols}\")\n",
    "\n",
    "# Compute industry-specific average stage per company age\n",
    "industry_stage_stats = (\n",
    "    df.groupby('category_code', observed=True)\n",
    "      .agg(\n",
    "          industry_avg_stage=('funding_stage_numeric', 'mean'),\n",
    "          industry_avg_age=('company_age_years_safe', 'mean')\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Merge industry benchmarks back to main df\n",
    "df = df.merge(industry_stage_stats, on='category_code', how='left')\n",
    "\n",
    "# Stage vs industry expectation\n",
    "df['stage_vs_industry_expectation'] = df['funding_stage_numeric'] - df['industry_avg_stage']\n",
    "\n",
    "# Industry progression percentile (rank within category by funding_stage_numeric)\n",
    "df['industry_progression_percentile'] = df.groupby('category_code')['funding_stage_numeric']\\\n",
    "                                         .rank(pct=True)\n",
    "\n",
    "# Sector stage advantage: positive if ahead of industry average\n",
    "df['sector_stage_advantage'] = df['funding_stage_numeric'] - df['industry_avg_stage']\n",
    "\n",
    "# Print validation outputs\n",
    "print(\"Sample industry stage benchmarking metrics:\")\n",
    "print(df[['category_code', 'funding_stage_numeric', 'industry_avg_stage', \n",
    "          'stage_vs_industry_expectation', 'industry_progression_percentile', \n",
    "          'sector_stage_advantage']].head(10).to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nAverage stage vs industry expectation: {df['stage_vs_industry_expectation'].mean():.2f}\")\n",
    "print(f\"Average industry progression percentile: {df['industry_progression_percentile'].mean():.2f}\")\n",
    "print(f\"Average sector stage advantage: {df['sector_stage_advantage'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db682b01",
   "metadata": {},
   "source": [
    "# 4. Bias Detection Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8a43e",
   "metadata": {},
   "source": [
    "## Step 1: Geographic Funding Bias Analysis\n",
    "\n",
    "```\n",
    "ALGORITHM: Geographic Bias Feature Engineering\n",
    "1. Calculate geographic funding bias indicators:\n",
    "   - State-level funding gaps vs national averages\n",
    "   - Regional funding bias patterns\n",
    "   - Urban vs rural funding accessibility\n",
    "\n",
    "2. Geographic Bias Features:\n",
    "   - state_funding_bias = company_funding - state_median_funding\n",
    "   - regional_funding_disadvantage = funding_gap_vs_regional_average\n",
    "   - geographic_funding_percentile = funding_percentile_within_state\n",
    "   - urban_rural_bias = funding_advantage_based_on_location_type\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- State-level funding bias analysis\n",
    "- Regional funding gap identification\n",
    "- Geographic disadvantage scoring\n",
    "- Urban/rural funding accessibility metrics\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fabd184b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     state  funding_total_usd  state_funding_bias       region  \\\n",
      "0  unknown         39750000.0          37185000.0      seattle   \n",
      "1  unknown                NaN                 NaN  los angeles   \n",
      "2  unknown                NaN                 NaN       sf bay   \n",
      "3  unknown                NaN                 NaN      unknown   \n",
      "4  unknown                NaN                 NaN      unknown   \n",
      "5  unknown                NaN                 NaN       agadir   \n",
      "6  unknown                NaN                 NaN     vadodara   \n",
      "7  unknown                NaN                 NaN      unknown   \n",
      "8  unknown                NaN                 NaN     new york   \n",
      "9  unknown                NaN                 NaN      unknown   \n",
      "\n",
      "   regional_funding_disadvantage  geographic_funding_percentile location_type  \\\n",
      "0                  -1.782740e+07                       0.915976       unknown   \n",
      "1                            NaN                            NaN       unknown   \n",
      "2                            NaN                            NaN       unknown   \n",
      "3                            NaN                            NaN       unknown   \n",
      "4                            NaN                            NaN       unknown   \n",
      "5                            NaN                            NaN       unknown   \n",
      "6                            NaN                            NaN       unknown   \n",
      "7                            NaN                            NaN       unknown   \n",
      "8                            NaN                            NaN       unknown   \n",
      "9                            NaN                            NaN       unknown   \n",
      "\n",
      "   urban_rural_bias  \n",
      "0        37185000.0  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "5               NaN  \n",
      "6               NaN  \n",
      "7               NaN  \n",
      "8               NaN  \n",
      "9               NaN  \n"
     ]
    }
   ],
   "source": [
    "# Ensure geographic columns exist\n",
    "if 'state' not in df.columns:\n",
    "    df['state'] = 'unknown'\n",
    "else:\n",
    "    df['state'] = df['state'].fillna('unknown')\n",
    "\n",
    "if 'region' not in df.columns:\n",
    "    df['region'] = 'unknown'\n",
    "else:\n",
    "    df['region'] = df['region'].fillna('unknown')\n",
    "\n",
    "if 'location_type' not in df.columns:\n",
    "    df['location_type'] = 'unknown'\n",
    "else:\n",
    "    df['location_type'] = df['location_type'].fillna('unknown')\n",
    "\n",
    "# Only compute metrics for rows with valid funding\n",
    "funding_mask = df['funding_total_usd'].notna()\n",
    "\n",
    "# State median funding\n",
    "state_median = (\n",
    "    df[funding_mask]\n",
    "    .groupby('state', observed=True)['funding_total_usd']\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .rename(columns={'funding_total_usd': 'state_median_funding'})\n",
    ")\n",
    "df = df.merge(state_median, on='state', how='left')\n",
    "\n",
    "# State funding bias\n",
    "df['state_funding_bias'] = df['funding_total_usd'] - df['state_median_funding']\n",
    "\n",
    "# Regional funding disadvantage\n",
    "region_avg = (\n",
    "    df[funding_mask]\n",
    "    .groupby('region', observed=True)['funding_total_usd']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'funding_total_usd': 'region_avg_funding'})\n",
    ")\n",
    "df = df.merge(region_avg, on='region', how='left')\n",
    "df['regional_funding_disadvantage'] = df['region_avg_funding'] - df['funding_total_usd']\n",
    "\n",
    "# Geographic funding percentile within state\n",
    "df['geographic_funding_percentile'] = df.groupby('state')['funding_total_usd']\\\n",
    "                                        .rank(pct=True, method='max')\n",
    "\n",
    "# Urban/rural bias\n",
    "df['urban_rural_bias'] = df.groupby('location_type')['funding_total_usd']\\\n",
    "                           .transform(lambda x: x - x.median())\n",
    "\n",
    "# Print validation\n",
    "print(df[['state', 'funding_total_usd', 'state_funding_bias', \n",
    "          'region', 'regional_funding_disadvantage',\n",
    "          'geographic_funding_percentile', 'location_type', 'urban_rural_bias']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6832e4a6",
   "metadata": {},
   "source": [
    "## Step 2: Industry Sector Bias Analysis\n",
    "\n",
    "```\n",
    "ALGORITHM: Industry Funding Bias Feature Engineering\n",
    "1. Identify industry-specific funding bias patterns:\n",
    "   - Sector funding preferences and discrimination\n",
    "   - Industry funding accessibility gaps\n",
    "   - Technology vs traditional industry bias\n",
    "\n",
    "2. Industry Bias Features:\n",
    "   - industry_funding_bias = company_funding - industry_median_funding\n",
    "   - sector_discrimination_score = funding_gap_vs_similar_companies\n",
    "   - tech_industry_advantage = funding_premium_for_tech_sectors\n",
    "   - traditional_industry_penalty = funding_disadvantage_for_traditional_sectors\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Industry funding bias matrix\n",
    "- Sector discrimination identification\n",
    "- Technology sector funding advantages\n",
    "- Traditional industry funding challenges\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5d5bcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     category_code  funding_total_usd  industry_median_funding  \\\n",
      "0              web         39750000.0                      0.0   \n",
      "1      games_video                0.0                      0.0   \n",
      "2      games_video                0.0                      0.0   \n",
      "3  network_hosting                0.0                      0.0   \n",
      "4      games_video                0.0                      0.0   \n",
      "5      advertising                0.0                      0.0   \n",
      "6        cleantech                0.0                  50000.0   \n",
      "7            other                0.0                      0.0   \n",
      "8      advertising                0.0                      0.0   \n",
      "9       enterprise                0.0                      0.0   \n",
      "\n",
      "   industry_funding_bias  sector_discrimination_score  \\\n",
      "0             39750000.0                 3.975000e+07   \n",
      "1                    0.0                 0.000000e+00   \n",
      "2                    0.0                 0.000000e+00   \n",
      "3                    0.0                 0.000000e+00   \n",
      "4                    0.0                 0.000000e+00   \n",
      "5                    0.0                 0.000000e+00   \n",
      "6               -50000.0                -9.999800e-01   \n",
      "7                    0.0                 0.000000e+00   \n",
      "8                    0.0                 0.000000e+00   \n",
      "9                    0.0                 0.000000e+00   \n",
      "\n",
      "   tech_industry_advantage  traditional_industry_penalty  \n",
      "0                      0.0                           0.0  \n",
      "1                      0.0                           0.0  \n",
      "2                      0.0                           0.0  \n",
      "3                      0.0                           0.0  \n",
      "4                      0.0                           0.0  \n",
      "5                      0.0                           0.0  \n",
      "6                      0.0                           0.0  \n",
      "7                      0.0                           0.0  \n",
      "8                      0.0                           0.0  \n",
      "9                      0.0                           0.0  \n",
      "\n",
      "Average industry funding bias: 2038354.81\n",
      "Average sector discrimination score: 1384951.61\n",
      "Companies with tech advantage >0: 7,410\n",
      "Companies with traditional penalty <0: 0\n"
     ]
    }
   ],
   "source": [
    "# Ensure columns exist\n",
    "if 'category_code' not in df.columns:\n",
    "    df['category_code'] = 'Unknown'\n",
    "else:\n",
    "    df['category_code'] = df['category_code'].fillna('Unknown')\n",
    "\n",
    "if 'funding_total_usd' not in df.columns:\n",
    "    df['funding_total_usd'] = 0\n",
    "else:\n",
    "    df['funding_total_usd'] = df['funding_total_usd'].fillna(0)\n",
    "\n",
    "# Industry median funding\n",
    "industry_median = df.groupby('category_code')['funding_total_usd'].median()\n",
    "df['industry_median_funding'] = df['category_code'].map(industry_median)\n",
    "\n",
    "# Industry funding bias\n",
    "df['industry_funding_bias'] = df['funding_total_usd'] - df['industry_median_funding']\n",
    "df['sector_discrimination_score'] = df['industry_funding_bias'] / (df['industry_median_funding'] + 1)\n",
    "\n",
    "# Define categories\n",
    "tech_categories = ['software', 'internet', 'biotech', 'hardware']\n",
    "traditional_categories = ['manufacturing', 'retail', 'construction']\n",
    "\n",
    "# Tech advantage and traditional penalty\n",
    "df['tech_industry_advantage'] = np.where(\n",
    "    df['category_code'].isin(tech_categories),\n",
    "    df['funding_total_usd'] - df['industry_median_funding'],\n",
    "    0\n",
    ")\n",
    "\n",
    "df['traditional_industry_penalty'] = np.where(\n",
    "    df['category_code'].isin(traditional_categories),\n",
    "    df['funding_total_usd'] - df['industry_median_funding'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# --- Print validation ---\n",
    "print(df[['category_code', 'funding_total_usd', 'industry_median_funding', \n",
    "          'industry_funding_bias', 'sector_discrimination_score', \n",
    "          'tech_industry_advantage', 'traditional_industry_penalty']].head(10))\n",
    "\n",
    "print(f\"\\nAverage industry funding bias: {df['industry_funding_bias'].mean():.2f}\")\n",
    "print(f\"Average sector discrimination score: {df['sector_discrimination_score'].mean():.2f}\")\n",
    "print(f\"Companies with tech advantage >0: {(df['tech_industry_advantage'] > 0).sum():,}\")\n",
    "print(f\"Companies with traditional penalty <0: {(df['traditional_industry_penalty'] < 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921d650",
   "metadata": {},
   "source": [
    "## Step 3: Temporal and Systemic Bias Analysis\n",
    "\n",
    "```\n",
    "ALGORITHM: Era and Systemic Bias Feature Engineering\n",
    "1. Analyze temporal funding bias patterns:\n",
    "   - Founding era bias (pre vs post financial crisis)\n",
    "   - Economic cycle impact on funding accessibility\n",
    "   - Systemic bias accumulation over time\n",
    "\n",
    "2. Temporal Bias Features:\n",
    "   - era_funding_bias = company_funding - era_median_funding\n",
    "   - economic_cycle_impact = funding_advantage_disadvantage_by_era\n",
    "   - systemic_bias_accumulation = combined_bias_score_across_dimensions\n",
    "   - funding_era_disadvantage = penalty_for_unfavorable_founding_timing\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Era-based funding bias analysis\n",
    "- Economic cycle impact assessment\n",
    "- Systemic bias accumulation scoring\n",
    "- Temporal disadvantage identification\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "195a1123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  founding_era  funding_total_usd  era_median_funding  era_funding_bias  \\\n",
      "0    2001-2008         39750000.0                 0.0        39750000.0   \n",
      "1    2001-2008                0.0                 0.0               0.0   \n",
      "2    2001-2008                0.0                 0.0               0.0   \n",
      "3    2001-2008                0.0                 0.0               0.0   \n",
      "4    2001-2008                0.0                 0.0               0.0   \n",
      "5    2001-2008                0.0                 0.0               0.0   \n",
      "6    2001-2008                0.0                 0.0               0.0   \n",
      "7    2009-2014                0.0                 0.0               0.0   \n",
      "8    2001-2008                0.0                 0.0               0.0   \n",
      "9    2009-2014                0.0                 0.0               0.0   \n",
      "\n",
      "  economic_cycle  economic_cycle_impact  systemic_bias_accumulation  \\\n",
      "0          other             39750000.0                1.192500e+08   \n",
      "1          other                    0.0                0.000000e+00   \n",
      "2          other                    0.0                0.000000e+00   \n",
      "3          other                    0.0                0.000000e+00   \n",
      "4          other                    0.0                0.000000e+00   \n",
      "5          other                    0.0                0.000000e+00   \n",
      "6          other                    0.0               -1.999980e+00   \n",
      "7          other                    0.0                0.000000e+00   \n",
      "8          other                    0.0                0.000000e+00   \n",
      "9          other                    0.0                0.000000e+00   \n",
      "\n",
      "   funding_era_disadvantage  \n",
      "0                         0  \n",
      "1                         0  \n",
      "2                         0  \n",
      "3                         0  \n",
      "4                         0  \n",
      "5                         0  \n",
      "6                         0  \n",
      "7                         0  \n",
      "8                         0  \n",
      "9                         0  \n",
      "\n",
      "Average era funding bias: 2101438.20\n",
      "Average economic cycle impact: 2101438.20\n",
      "Average systemic bias accumulation: 4871341.43\n",
      "Average funding era disadvantage: 0.00\n",
      "\n",
      "Company counts by founding era:\n",
      "founding_era\n",
      "2009-2014    148589\n",
      "2001-2008     33147\n",
      "1991-2000      9967\n",
      "Pre-1990       4827\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Company counts by economic cycle:\n",
      "economic_cycle\n",
      "other    196530\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure founding_era and funding_total_usd exist\n",
    "df['founding_era'] = df.get('founding_era', 'Unknown')\n",
    "df['funding_total_usd'] = df.get('funding_total_usd', 0)\n",
    "\n",
    "# Compute era median funding\n",
    "era_median_funding = df.groupby('founding_era')['funding_total_usd'].median()\n",
    "df['era_median_funding'] = df['founding_era'].map(era_median_funding)\n",
    "\n",
    "# Era funding bias\n",
    "df['era_funding_bias'] = df['funding_total_usd'] - df['era_median_funding']\n",
    "\n",
    "# Economic cycle impact\n",
    "# Example: Define eras by economic cycles, then compute relative deviation\n",
    "economic_cycles = {\n",
    "    'pre_2008': ['pre_2000', '2000-2007'],\n",
    "    'post_2008': ['2008-2015', '2016+']\n",
    "}\n",
    "\n",
    "# Map eras to cycles\n",
    "def map_cycle(era):\n",
    "    for cycle, eras in economic_cycles.items():\n",
    "        if era in eras:\n",
    "            return cycle\n",
    "    return 'other'\n",
    "\n",
    "df['economic_cycle'] = df['founding_era'].map(map_cycle)\n",
    "\n",
    "# Compute average funding per cycle\n",
    "cycle_median_funding = df.groupby('economic_cycle')['funding_total_usd'].median()\n",
    "df['economic_cycle_impact'] = df['economic_cycle'].map(cycle_median_funding)\n",
    "df['economic_cycle_impact'] = df['funding_total_usd'] - df['economic_cycle_impact']\n",
    "\n",
    "# Systemic bias accumulation\n",
    "# Sum normalized biases across dimensions (industry, era, sector)\n",
    "df['systemic_bias_accumulation'] = (\n",
    "    df.get('industry_funding_bias', 0)/df['industry_median_funding'].replace(0,1) +\n",
    "    df['era_funding_bias']/df['era_median_funding'].replace(0,1) +\n",
    "    df.get('sector_discrimination_score', 0)\n",
    ")\n",
    "\n",
    "# Funding era disadvantage\n",
    "# Penalize eras with median funding below overall median\n",
    "overall_median = df['funding_total_usd'].median()\n",
    "df['funding_era_disadvantage'] = df['era_median_funding'].apply(lambda x: max(0, overall_median - x))\n",
    "\n",
    "print(df[['founding_era', 'funding_total_usd', 'era_median_funding', \n",
    "          'era_funding_bias', 'economic_cycle', 'economic_cycle_impact', \n",
    "          'systemic_bias_accumulation', 'funding_era_disadvantage']].head(10))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nAverage era funding bias: {df['era_funding_bias'].mean():.2f}\")\n",
    "print(f\"Average economic cycle impact: {df['economic_cycle_impact'].mean():.2f}\")\n",
    "print(f\"Average systemic bias accumulation: {df['systemic_bias_accumulation'].mean():.2f}\")\n",
    "print(f\"Average funding era disadvantage: {df['funding_era_disadvantage'].mean():.2f}\")\n",
    "\n",
    "# Optional: counts per era and cycle\n",
    "print(\"\\nCompany counts by founding era:\")\n",
    "print(df['founding_era'].value_counts())\n",
    "print(\"\\nCompany counts by economic cycle:\")\n",
    "print(df['economic_cycle'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca99e311",
   "metadata": {},
   "source": [
    "# 5. Geographic Heatmap-Ready Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f59c8",
   "metadata": {},
   "source": [
    "## Step 1: State-Level Aggregation Features\n",
    "\n",
    "```\n",
    "ALGORITHM: State-Level Heatmap Data Preparation\n",
    "1. Create state-level startup ecosystem metrics:\n",
    "   - Startup density per state (companies per capita)\n",
    "   - State success rate aggregations\n",
    "   - State funding concentration metrics\n",
    "   - State risk profile aggregations\n",
    "\n",
    "2. State Aggregation Features:\n",
    "   - state_startup_density = companies_in_state / state_population_proxy\n",
    "   - state_success_rate = success_rate_for_companies_in_state\n",
    "   - state_avg_funding = average_funding_amount_in_state\n",
    "   - state_risk_score = average_risk_score_for_state\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- State-level startup ecosystem metrics\n",
    "- Success rate heatmap data by state\n",
    "- Funding concentration heatmap data\n",
    "- Risk profile geographic distribution\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab7a4075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state_code  companies_in_state  state_success_rate  state_avg_funding  \\\n",
      "0         ak                  16            0.187500       3.188881e+05   \n",
      "1         al                 178            0.286517       8.323243e+06   \n",
      "2         ar                  85            0.270588       2.522311e+06   \n",
      "3         az                 760            0.223684       2.821740e+06   \n",
      "4         ca               16488            0.372877       8.354919e+06   \n",
      "5         co                1173            0.367434       5.286005e+06   \n",
      "6         ct                 537            0.374302       4.368240e+06   \n",
      "7         dc                 373            0.227882       4.059957e+06   \n",
      "8         de                 181            0.171271       1.920272e+06   \n",
      "9         fl                2154            0.208914       2.738450e+06   \n",
      "\n",
      "   state_risk_score  state_startup_density  \n",
      "0          1.687500                    NaN  \n",
      "1          1.494382                    NaN  \n",
      "2          1.541176                    NaN  \n",
      "3          1.607895                    NaN  \n",
      "4          1.306283                    NaN  \n",
      "5          1.346121                    NaN  \n",
      "6          1.335196                    NaN  \n",
      "7          1.608579                    NaN  \n",
      "8          1.718232                    NaN  \n",
      "9          1.637883                    NaN  \n",
      "\n",
      "Average state startup density: nan\n",
      "Average state success rate: 30.34%\n",
      "Average state funding: $3,570,676.90\n",
      "Average state risk score: 1.47\n",
      "\n",
      "Companies per state:\n",
      "   state_code  companies_in_state\n",
      "44    unknown              145629\n",
      "4          ca               16488\n",
      "34         ny                5732\n",
      "19         ma                2937\n",
      "43         tx                2811\n",
      "9          fl                2154\n",
      "48         wa                1894\n",
      "14         il                1742\n",
      "38         pa                1322\n",
      "31         nj                1182\n",
      "5          co                1173\n",
      "46         va                1157\n",
      "10         ga                1126\n",
      "27         nc                 845\n",
      "20         md                 772\n",
      "3          az                 760\n",
      "35         oh                 760\n",
      "23         mn                 669\n",
      "22         mi                 632\n",
      "37         or                 592\n",
      "45         ut                 568\n",
      "42         tn                 549\n",
      "6          ct                 537\n",
      "33         nv                 401\n",
      "24         mo                 399\n",
      "7          dc                 373\n",
      "15         in                 349\n",
      "49         wi                 345\n",
      "30         nh                 220\n",
      "17         ky                 218\n",
      "40         sc                 195\n",
      "8          de                 181\n",
      "1          al                 178\n",
      "16         ks                 175\n",
      "39         ri                 154\n",
      "36         ok                 145\n",
      "18         la                 139\n",
      "29         ne                 128\n",
      "12         ia                 118\n",
      "21         me                 102\n",
      "13         id                  98\n",
      "47         vt                  90\n",
      "32         nm                  87\n",
      "2          ar                  85\n",
      "11         hi                  85\n",
      "26         mt                  70\n",
      "25         ms                  44\n",
      "28         nd                  31\n",
      "50         wv                  26\n",
      "41         sd                  26\n",
      "51         wy                  21\n",
      "0          ak                  16\n"
     ]
    }
   ],
   "source": [
    "# Ensure state_code exists\n",
    "df['state_code'] = df.get('state_code', 'Unknown')\n",
    "\n",
    "# Example: mock state population proxy if not available\n",
    "# Replace with real population data if available\n",
    "state_population = {\n",
    "    'CA': 39538223, 'NY': 20201249, 'TX': 29145505, 'Unknown': 1\n",
    "}\n",
    "df['state_population'] = df['state_code'].map(lambda x: state_population.get(x, 1))\n",
    "\n",
    "# Aggregate state-level metrics\n",
    "state_stats = df.groupby('state_code').agg(\n",
    "    companies_in_state=('id', 'count'),\n",
    "    state_success_rate=('failure_risk', lambda x: 1 - x.mean() if len(x) > 0 else np.nan),\n",
    "    state_avg_funding=('funding_total_usd', 'mean'),\n",
    "    state_risk_score=('risk_tier', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Compute density per population proxy\n",
    "state_stats['state_startup_density'] = state_stats['companies_in_state'] / state_stats['state_code'].map(state_population)\n",
    "\n",
    "# Merge back to main dataframe\n",
    "df = df.merge(\n",
    "    state_stats[['state_code', 'state_startup_density', 'state_success_rate', 'state_avg_funding', 'state_risk_score']],\n",
    "    on='state_code',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(state_stats.head(10))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nAverage state startup density: {state_stats['state_startup_density'].mean():.6f}\")\n",
    "print(f\"Average state success rate: {state_stats['state_success_rate'].mean():.2%}\")\n",
    "print(f\"Average state funding: ${state_stats['state_avg_funding'].mean():,.2f}\")\n",
    "print(f\"Average state risk score: {state_stats['state_risk_score'].mean():.2f}\")\n",
    "\n",
    "# Optional: distribution of companies per state\n",
    "print(\"\\nCompanies per state:\")\n",
    "print(state_stats[['state_code', 'companies_in_state']].sort_values('companies_in_state', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ba4ea",
   "metadata": {},
   "source": [
    "## Step 2: Regional and Metropolitan Area Features\n",
    "\n",
    "```\n",
    "ALGORITHM: Regional Heatmap Granularity Enhancement\n",
    "1. Create multi-level geographic aggregations:\n",
    "   - Regional startup ecosystem analysis\n",
    "   - Metropolitan area startup concentrations\n",
    "   - Rural vs urban startup patterns\n",
    "\n",
    "2. Regional Features:\n",
    "   - region_startup_concentration = startup_density_by_region\n",
    "   - metro_area_advantage = funding_advantage_in_major_cities\n",
    "   - rural_startup_challenges = disadvantages_outside_major_metros\n",
    "   - geographic_cluster_strength = startup_ecosystem_network_effects\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Regional startup concentration analysis\n",
    "- Metropolitan area ecosystem strength\n",
    "- Rural startup ecosystem challenges\n",
    "- Geographic cluster network effects\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffd1733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure region and city exist\n",
    "df['region'] = df.get('region', 'Unknown')\n",
    "df['city'] = df.get('city', 'Unknown')\n",
    "\n",
    "# Regional startup concentration and metrics\n",
    "region_stats = df.groupby('region').agg(\n",
    "    region_startup_count=('id', 'count'),\n",
    "    region_avg_funding_region=('funding_total_usd', 'mean'),\n",
    "    region_success_rate=('failure_risk', lambda x: 1 - x.mean() if len(x) > 0 else np.nan)\n",
    ").reset_index()\n",
    "\n",
    "# Max region count for normalization\n",
    "max_region_count = region_stats['region_startup_count'].max()\n",
    "region_stats['geographic_cluster_strength'] = region_stats['region_startup_count'] / max_region_count\n",
    "\n",
    "# Merge regional metrics back to main dataframe\n",
    "df = df.merge(region_stats, on='region', how='left')\n",
    "\n",
    "# Metro area flag\n",
    "major_metros = ['San Francisco', 'New York', 'Los Angeles', 'Boston', 'Chicago']\n",
    "df['metro_area_flag'] = df['city'].isin(major_metros).astype(int)\n",
    "\n",
    "# Metro area funding advantage (vectorized)\n",
    "metro_avg_funding = df.loc[df['metro_area_flag'] == 1, 'funding_total_usd'].mean()\n",
    "df['metro_area_advantage'] = np.where(df['metro_area_flag'] == 1,\n",
    "                                      df['funding_total_usd'] - metro_avg_funding,\n",
    "                                      0)\n",
    "\n",
    "# Rural startup challenges (vectorized)\n",
    "df['rural_startup_challenges'] = np.where(df['metro_area_flag'] == 0,\n",
    "                                          metro_avg_funding - df['funding_total_usd'],\n",
    "                                          0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b089b0",
   "metadata": {},
   "source": [
    "## Step 3: Geographic Investment Opportunity Mapping\n",
    "\n",
    "```\n",
    "ALGORITHM: Investment Opportunity Geographic Features\n",
    "1. Create investment opportunity geographic indicators:\n",
    "   - Under-capitalized geographic concentrations\n",
    "   - High-potential low-funded geographic areas\n",
    "   - Geographic arbitrage opportunities\n",
    "\n",
    "2. Geographic Opportunity Features:\n",
    "   - state_undercap_concentration = undercap_companies_per_state / total_state_companies\n",
    "   - geographic_opportunity_score = high_potential_low_funded_areas\n",
    "   - state_investment_gap = funding_opportunity_vs_current_investment\n",
    "   - regional_arbitrage_potential = undervalued_geographic_markets\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Under-capitalized geographic concentration heatmap data\n",
    "- Investment opportunity geographic scoring\n",
    "- Geographic funding gap analysis\n",
    "- Regional investment arbitrage identification\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "caa79c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographic features created successfully:\n",
      "Average state under-cap concentration: 0.861\n",
      "Average geographic opportunity score: 7154564.67\n",
      "Average state investment gap: $7,930,207.16\n",
      "Average regional arbitrage potential: 0.0000\n",
      "\n",
      "Top 10 states by geographic opportunity:\n",
      "            state_undercap_concentration  geographic_opportunity_score\n",
      "state_code                                                            \n",
      "unknown                         0.934203                  8.706411e+06\n",
      "ak                              0.750000                  7.284568e+06\n",
      "wy                              0.714286                  6.729475e+06\n",
      "nv                              0.760599                  6.671900e+06\n",
      "de                              0.812155                  6.587690e+06\n",
      "ky                              0.711009                  6.374389e+06\n",
      "wv                              0.692308                  6.294219e+06\n",
      "nd                              0.774194                  6.252254e+06\n",
      "sd                              0.730769                  6.168950e+06\n",
      "mi                              0.740506                  6.152769e+06\n"
     ]
    }
   ],
   "source": [
    "# Ensure necessary columns exist\n",
    "df['state_code'] = df.get('state_code', 'Unknown')\n",
    "df['under_capitalized'] = df.get('under_capitalized', 0)\n",
    "\n",
    "# First, remove any existing geographic columns to avoid duplicates\n",
    "columns_to_remove = ['state_undercap_concentration', 'state_avg_funding', \n",
    "                    'geographic_opportunity_score', 'state_investment_gap', \n",
    "                    'regional_arbitrage_potential']\n",
    "df = df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "\n",
    "# State-level under-capitalized concentration\n",
    "state_undercap_stats = df.groupby('state_code').agg(\n",
    "    total_state_companies=('id', 'count'),\n",
    "    undercap_companies=('under_capitalized', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "state_undercap_stats['state_undercap_concentration'] = (\n",
    "    state_undercap_stats['undercap_companies'] / state_undercap_stats['total_state_companies']\n",
    ")\n",
    "\n",
    "# Merge back\n",
    "df = df.merge(state_undercap_stats[['state_code', 'state_undercap_concentration']], \n",
    "              on='state_code', how='left')\n",
    "\n",
    "# State average funding\n",
    "state_avg_funding = df.groupby('state_code')['funding_total_usd'].mean().reset_index()\n",
    "state_avg_funding = state_avg_funding.rename(columns={'funding_total_usd': 'state_avg_funding'})\n",
    "\n",
    "# Merge state average funding with suffixes to handle duplicates\n",
    "df = df.merge(state_avg_funding, on='state_code', how='left', suffixes=('', '_state'))\n",
    "\n",
    "# Now create the geographic features\n",
    "df['geographic_opportunity_score'] = df['state_undercap_concentration'] * (\n",
    "    df['state_avg_funding'].max() - df['state_avg_funding']\n",
    ")\n",
    "\n",
    "# State investment gap\n",
    "df['state_investment_gap'] = df['state_avg_funding'].max() - df['state_avg_funding']\n",
    "\n",
    "# Regional arbitrage potential (handle division by zero)\n",
    "df['regional_arbitrage_potential'] = df['state_undercap_concentration'] / df['state_avg_funding'].replace(0, 1)\n",
    "\n",
    "# Validation\n",
    "print(\"Geographic features created successfully:\")\n",
    "print(f\"Average state under-cap concentration: {df['state_undercap_concentration'].mean():.3f}\")\n",
    "print(f\"Average geographic opportunity score: {df['geographic_opportunity_score'].mean():.2f}\")\n",
    "print(f\"Average state investment gap: ${df['state_investment_gap'].mean():,.2f}\")\n",
    "print(f\"Average regional arbitrage potential: {df['regional_arbitrage_potential'].mean():.4f}\")\n",
    "\n",
    "# Check top opportunity states\n",
    "top_opportunity = df.groupby('state_code').agg({\n",
    "    'state_undercap_concentration': 'mean',\n",
    "    'geographic_opportunity_score': 'mean'\n",
    "}).nlargest(10, 'geographic_opportunity_score')\n",
    "\n",
    "print(f\"\\nTop 10 states by geographic opportunity:\")\n",
    "print(top_opportunity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2517d711",
   "metadata": {},
   "source": [
    "# 6. Feature Quality Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71b794",
   "metadata": {},
   "source": [
    "## Step 1: Feature Quality Assessment\n",
    "\n",
    "```\n",
    "ALGORITHM: Feature Engineering Quality Control\n",
    "1. Validate all engineered features for ML readiness:\n",
    "   - Check for infinite values and extreme outliers\n",
    "   - Assess feature correlation with target variables\n",
    "   - Identify multicollinearity issues\n",
    "   - Validate feature distributions and scaling needs\n",
    "\n",
    "2. Quality Control Checks:\n",
    "   - infinite_values_check = identify_features_with_infinite_values\n",
    "   - target_correlation_analysis = correlation_with_failure_risk_and_success\n",
    "   - multicollinearity_assessment = identify_highly_correlated_features\n",
    "   - feature_distribution_analysis = assess_scaling_and_normalization_needs\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Feature quality report: \"X features ready, X need attention\"\n",
    "- Target correlation ranking: Top 20 most predictive features\n",
    "- Multicollinearity identification: Features with >0.9 correlation\n",
    "- Scaling requirements: Features needing normalization\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18f16e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with infinite values:\n",
      "industry_growth_rate     547\n",
      "age_industry_maturity    547\n",
      "dtype: int64\n",
      "\n",
      "Features with extreme outliers (IQR > 3*IQR rule):\n",
      "{'lat': np.int64(2647), 'founded_year': np.int64(8209), 'company_age_years': np.int64(8209), 'funding_total_usd': np.int64(27873), 'funding_rounds': np.int64(31705), 'has_funding': np.int64(27873), 'months_to_first_funding': np.int64(35020), 'months_since_last_funding': np.int64(100), 'milestones': np.int64(217), 'investment_rounds': np.int64(2589), 'invested_companies': np.int64(2589), 'failure_risk': np.int64(25999), 'risk_tier': np.int64(25999), 'funding_velocity': np.int64(2010), 'funding_vs_avg': np.int64(2093), 'funding_vs_industry_avg': np.int64(1940), 'industry_growth_rate': np.int64(448), 'stage_risk_mean': np.int64(35941), 'age_funding_ratio': np.int64(2266), 'age_funding_velocity': np.int64(2093), 'funding_industry_fit': np.int64(2162), 'age_industry_maturity': np.int64(1249), 'years_since_founding': np.int64(8209), 'funding_efficiency': np.int64(2012), 'funding_momentum': np.int64(2107), 'era_adjusted_funding': np.int64(2056), 'risk_vs_country_peers': np.int64(25980), 'risk_vs_industry_peers': np.int64(25745), 'risk_vs_stage_peers': np.int64(36421), 'funding_vs_age_expectation': np.int64(2519), 'funding_vs_era_expectation': np.int64(2548), 'peer_performance_score': np.int64(2290), 'investment_activity_score': np.int64(2589), 'investment_to_funding_ratio': np.int64(2589), 'relationships_count': np.int64(6726), 'network_connectivity': np.int64(6905), 'milestones_per_year': np.int64(37), 'achievement_score': np.int64(1829), 'subdomain_count': np.int64(8536), 'overview_length': np.int64(1990), 'tag_count': np.int64(1873), 'avg_tag_length': np.int64(1485), 'funding_duration_days': np.int64(11012), 'time_to_first_funding_days': np.int64(1588), 'time_to_first_funding_years': np.int64(1588), 'milestone_duration_days': np.int64(13373), 'days_since_last_funding': np.int64(357), 'days_since_last_milestone': np.int64(8901), 'funding_frequency': np.int64(31705), 'strategic_positioning': np.int64(2025), 'undercap_survival_months': np.int64(8209), 'bootstrap_efficiency': np.int64(45), 'undercap_longevity_score': np.int64(11631), 'undercap_peer_success_rate': np.int64(3519), 'undercap_peer_avg_survival': np.int64(33194), 'undercap_peer_avg_efficiency': np.int64(86), 'undercap_peer_survival_comparison': np.int64(919), 'minimal_funding_long_survivor': np.int64(27314), 'bootstrap_milestone_velocity': np.int64(13801), 'organic_growth_indicator': np.int64(37), 'growth_without_vc': np.int64(3276), 'team_network_strength': np.int64(6726), 'company_age_years_safe': np.int64(8209), 'time_in_current_stage': np.int64(100), 'stuck_in_early_stage': np.int64(19995), 'progression_risk_score': np.int64(35), 'industry_avg_stage': np.int64(38090), 'state_funding_bias': np.int64(2093), 'region_avg_funding': np.int64(2735), 'regional_funding_disadvantage': np.int64(1271), 'urban_rural_bias': np.int64(2093), 'industry_median_funding': np.int64(9607), 'industry_funding_bias': np.int64(31404), 'sector_discrimination_score': np.int64(31404), 'tech_industry_advantage': np.int64(9625), 'traditional_industry_penalty': np.int64(327), 'era_funding_bias': np.int64(27873), 'economic_cycle_impact': np.int64(27873), 'systemic_bias_accumulation': np.int64(31417), 'region_avg_funding_region': np.int64(14762), 'region_success_rate': np.int64(791), 'metro_area_flag': np.int64(10201), 'metro_area_advantage': np.int64(10201), 'rural_startup_challenges': np.int64(34266), 'state_avg_funding': np.int64(33500), 'state_investment_gap': np.int64(33500)}\n",
      "\n",
      "Top 20 features correlated with failure_risk:\n",
      "risk_tier                        0.968730\n",
      "has_funding                     -0.960477\n",
      "minimal_funding_long_survivor    0.957318\n",
      "stage_risk_mean                  0.939940\n",
      "risk_vs_country_peers            0.905835\n",
      "risk_vs_industry_peers           0.899575\n",
      "funding_frequency               -0.854133\n",
      "funding_rounds                  -0.748466\n",
      "stuck_in_early_stage            -0.727542\n",
      "months_to_first_funding          0.527836\n",
      "geo_industry_risk                0.492037\n",
      "region_success_rate             -0.488723\n",
      "achievement_score               -0.467986\n",
      "industry_risk_mean               0.436767\n",
      "undercap_sector_density          0.436495\n",
      "funding_duration_days           -0.433460\n",
      "country_risk_mean                0.423630\n",
      "undercap_geographic_density      0.423400\n",
      "progression_risk_score           0.411169\n",
      "region_startup_count             0.383304\n",
      "Name: failure_risk, dtype: float64\n",
      "\n",
      "Alternative approach - Top 20 features correlated with failure_risk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emily\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\emily\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failure_risk                     1.000000\n",
      "risk_tier                        0.968730\n",
      "has_funding                     -0.960477\n",
      "minimal_funding_long_survivor    0.957318\n",
      "stage_risk_mean                  0.939940\n",
      "risk_vs_country_peers            0.905835\n",
      "risk_vs_industry_peers           0.899575\n",
      "funding_frequency               -0.854133\n",
      "funding_rounds                  -0.748466\n",
      "stuck_in_early_stage            -0.727542\n",
      "months_to_first_funding          0.527836\n",
      "geo_industry_risk                0.492037\n",
      "region_success_rate             -0.488723\n",
      "achievement_score               -0.467986\n",
      "industry_risk_mean               0.436767\n",
      "undercap_sector_density          0.436495\n",
      "funding_duration_days           -0.433460\n",
      "country_risk_mean                0.423630\n",
      "undercap_geographic_density      0.423400\n",
      "progression_risk_score           0.411169\n",
      "dtype: float64\n",
      "\n",
      "Highly correlated feature pairs (|corr| > 0.9):\n",
      "founded_year & company_age_years = 0.94\n",
      "founded_year & years_since_founding = 1.00\n",
      "founded_year & undercap_survival_months = 0.94\n",
      "founded_year & undercap_longevity_score = 0.90\n",
      "founded_year & company_age_years_safe = 0.94\n",
      "company_age_years & years_since_founding = 0.94\n",
      "company_age_years & undercap_survival_months = 1.00\n",
      "company_age_years & undercap_longevity_score = 0.94\n",
      "company_age_years & undercap_peer_avg_survival = 0.96\n",
      "company_age_years & company_age_years_safe = 1.00\n",
      "funding_total_usd & funding_velocity = 0.98\n",
      "funding_total_usd & funding_vs_avg = 1.00\n",
      "funding_total_usd & funding_vs_industry_avg = 0.94\n",
      "funding_total_usd & age_funding_ratio = 0.95\n",
      "funding_total_usd & age_funding_velocity = 1.00\n",
      "funding_total_usd & funding_efficiency = 0.98\n",
      "funding_total_usd & funding_vs_age_expectation = 1.00\n",
      "funding_total_usd & funding_vs_era_expectation = 1.00\n",
      "funding_total_usd & peer_performance_score = 0.93\n",
      "funding_total_usd & strategic_positioning = 0.94\n",
      "funding_total_usd & state_funding_bias = 1.00\n",
      "funding_total_usd & regional_funding_disadvantage = 0.98\n",
      "funding_total_usd & urban_rural_bias = 1.00\n",
      "funding_total_usd & industry_funding_bias = 1.00\n",
      "funding_total_usd & era_funding_bias = 1.00\n",
      "funding_total_usd & economic_cycle_impact = 1.00\n",
      "funding_total_usd & systemic_bias_accumulation = 0.96\n",
      "has_funding & failure_risk = 0.96\n",
      "has_funding & risk_tier = 0.93\n",
      "has_funding & stage_risk_mean = 0.91\n",
      "has_funding & minimal_funding_long_survivor = 0.99\n",
      "months_to_first_funding & time_to_first_funding_days = 1.00\n",
      "months_to_first_funding & time_to_first_funding_years = 1.00\n",
      "months_since_last_funding & days_since_last_funding = 1.00\n",
      "months_since_last_funding & time_in_current_stage = 1.00\n",
      "milestones & milestones_per_year = 0.96\n",
      "milestones & achievement_score = 0.92\n",
      "milestones & organic_growth_indicator = 0.96\n",
      "investment_rounds & invested_companies = 1.00\n",
      "investment_rounds & investment_activity_score = 1.00\n",
      "invested_companies & investment_activity_score = 1.00\n",
      "failure_risk & risk_tier = 0.97\n",
      "failure_risk & stage_risk_mean = 0.94\n",
      "failure_risk & risk_vs_country_peers = 0.91\n",
      "failure_risk & minimal_funding_long_survivor = 0.96\n",
      "risk_tier & minimal_funding_long_survivor = 0.93\n",
      "funding_velocity & funding_vs_avg = 0.98\n",
      "funding_velocity & funding_vs_industry_avg = 0.91\n",
      "funding_velocity & age_funding_velocity = 0.98\n",
      "funding_velocity & funding_efficiency = 1.00\n",
      "funding_velocity & funding_vs_age_expectation = 0.98\n",
      "funding_velocity & funding_vs_era_expectation = 0.98\n",
      "funding_velocity & peer_performance_score = 0.90\n",
      "funding_velocity & strategic_positioning = 0.91\n",
      "funding_velocity & state_funding_bias = 0.98\n",
      "funding_velocity & regional_funding_disadvantage = 0.96\n",
      "funding_velocity & urban_rural_bias = 0.98\n",
      "funding_velocity & industry_funding_bias = 0.98\n",
      "funding_velocity & era_funding_bias = 0.98\n",
      "funding_velocity & economic_cycle_impact = 0.98\n",
      "funding_velocity & systemic_bias_accumulation = 0.93\n",
      "funding_vs_avg & funding_vs_industry_avg = 0.94\n",
      "funding_vs_avg & age_funding_ratio = 0.95\n",
      "funding_vs_avg & age_funding_velocity = 1.00\n",
      "funding_vs_avg & funding_efficiency = 0.98\n",
      "funding_vs_avg & funding_vs_age_expectation = 1.00\n",
      "funding_vs_avg & funding_vs_era_expectation = 1.00\n",
      "funding_vs_avg & peer_performance_score = 0.93\n",
      "funding_vs_avg & strategic_positioning = 0.94\n",
      "funding_vs_avg & state_funding_bias = 1.00\n",
      "funding_vs_avg & regional_funding_disadvantage = 0.98\n",
      "funding_vs_avg & urban_rural_bias = 1.00\n",
      "funding_vs_avg & industry_funding_bias = 1.00\n",
      "funding_vs_avg & era_funding_bias = 1.00\n",
      "funding_vs_avg & economic_cycle_impact = 1.00\n",
      "funding_vs_avg & systemic_bias_accumulation = 0.95\n",
      "funding_vs_industry_avg & age_funding_ratio = 0.91\n",
      "funding_vs_industry_avg & age_funding_velocity = 0.94\n",
      "funding_vs_industry_avg & funding_industry_fit = 0.92\n",
      "funding_vs_industry_avg & funding_efficiency = 0.91\n",
      "funding_vs_industry_avg & funding_vs_age_expectation = 0.94\n",
      "funding_vs_industry_avg & funding_vs_era_expectation = 0.94\n",
      "funding_vs_industry_avg & peer_performance_score = 0.99\n",
      "funding_vs_industry_avg & strategic_positioning = 1.00\n",
      "funding_vs_industry_avg & state_funding_bias = 0.94\n",
      "funding_vs_industry_avg & regional_funding_disadvantage = 0.92\n",
      "funding_vs_industry_avg & urban_rural_bias = 0.94\n",
      "funding_vs_industry_avg & industry_funding_bias = 0.94\n",
      "funding_vs_industry_avg & sector_discrimination_score = 0.92\n",
      "funding_vs_industry_avg & era_funding_bias = 0.94\n",
      "funding_vs_industry_avg & economic_cycle_impact = 0.94\n",
      "funding_vs_industry_avg & systemic_bias_accumulation = 0.95\n",
      "industry_growth_rate & age_industry_maturity = 0.92\n",
      "country_risk_mean & undercap_geographic_density = 1.00\n",
      "country_risk_mean & region_startup_count = 0.91\n",
      "country_risk_mean & geographic_cluster_strength = 0.91\n",
      "country_risk_confidence & region_startup_count = 0.91\n",
      "country_risk_confidence & geographic_cluster_strength = 0.91\n",
      "industry_risk_mean & undercap_sector_density = 1.00\n",
      "industry_risk_confidence & undercap_peer_count = 0.92\n",
      "age_funding_ratio & age_funding_velocity = 0.95\n",
      "age_funding_ratio & funding_vs_age_expectation = 0.95\n",
      "age_funding_ratio & funding_vs_era_expectation = 0.95\n",
      "age_funding_ratio & strategic_positioning = 0.91\n",
      "age_funding_ratio & state_funding_bias = 0.95\n",
      "age_funding_ratio & regional_funding_disadvantage = 0.92\n",
      "age_funding_ratio & urban_rural_bias = 0.95\n",
      "age_funding_ratio & industry_funding_bias = 0.95\n",
      "age_funding_ratio & era_funding_bias = 0.95\n",
      "age_funding_ratio & economic_cycle_impact = 0.95\n",
      "age_funding_ratio & systemic_bias_accumulation = 0.92\n",
      "age_funding_velocity & funding_efficiency = 0.98\n",
      "age_funding_velocity & funding_vs_age_expectation = 1.00\n",
      "age_funding_velocity & funding_vs_era_expectation = 1.00\n",
      "age_funding_velocity & peer_performance_score = 0.93\n",
      "age_funding_velocity & strategic_positioning = 0.94\n",
      "age_funding_velocity & state_funding_bias = 1.00\n",
      "age_funding_velocity & regional_funding_disadvantage = 0.98\n",
      "age_funding_velocity & urban_rural_bias = 1.00\n",
      "age_funding_velocity & industry_funding_bias = 1.00\n",
      "age_funding_velocity & era_funding_bias = 1.00\n",
      "age_funding_velocity & economic_cycle_impact = 1.00\n",
      "age_funding_velocity & systemic_bias_accumulation = 0.95\n",
      "funding_industry_fit & peer_performance_score = 0.91\n",
      "funding_industry_fit & strategic_positioning = 0.92\n",
      "years_since_founding & undercap_survival_months = 0.94\n",
      "years_since_founding & undercap_longevity_score = 0.90\n",
      "years_since_founding & company_age_years_safe = 0.94\n",
      "funding_efficiency & funding_vs_age_expectation = 0.98\n",
      "funding_efficiency & funding_vs_era_expectation = 0.98\n",
      "funding_efficiency & peer_performance_score = 0.90\n",
      "funding_efficiency & strategic_positioning = 0.91\n",
      "funding_efficiency & state_funding_bias = 0.98\n",
      "funding_efficiency & regional_funding_disadvantage = 0.96\n",
      "funding_efficiency & urban_rural_bias = 0.98\n",
      "funding_efficiency & industry_funding_bias = 0.98\n",
      "funding_efficiency & era_funding_bias = 0.98\n",
      "funding_efficiency & economic_cycle_impact = 0.98\n",
      "funding_efficiency & systemic_bias_accumulation = 0.93\n",
      "funding_vs_age_expectation & funding_vs_era_expectation = 1.00\n",
      "funding_vs_age_expectation & peer_performance_score = 0.93\n",
      "funding_vs_age_expectation & strategic_positioning = 0.94\n",
      "funding_vs_age_expectation & state_funding_bias = 1.00\n",
      "funding_vs_age_expectation & regional_funding_disadvantage = 0.98\n",
      "funding_vs_age_expectation & urban_rural_bias = 1.00\n",
      "funding_vs_age_expectation & industry_funding_bias = 1.00\n",
      "funding_vs_age_expectation & era_funding_bias = 1.00\n",
      "funding_vs_age_expectation & economic_cycle_impact = 1.00\n",
      "funding_vs_age_expectation & systemic_bias_accumulation = 0.95\n",
      "funding_vs_era_expectation & peer_performance_score = 0.93\n",
      "funding_vs_era_expectation & strategic_positioning = 0.94\n",
      "funding_vs_era_expectation & state_funding_bias = 1.00\n",
      "funding_vs_era_expectation & regional_funding_disadvantage = 0.98\n",
      "funding_vs_era_expectation & urban_rural_bias = 1.00\n",
      "funding_vs_era_expectation & industry_funding_bias = 1.00\n",
      "funding_vs_era_expectation & era_funding_bias = 1.00\n",
      "funding_vs_era_expectation & economic_cycle_impact = 1.00\n",
      "funding_vs_era_expectation & systemic_bias_accumulation = 0.95\n",
      "peer_performance_score & strategic_positioning = 0.99\n",
      "peer_performance_score & state_funding_bias = 0.93\n",
      "peer_performance_score & regional_funding_disadvantage = 0.91\n",
      "peer_performance_score & urban_rural_bias = 0.93\n",
      "peer_performance_score & industry_funding_bias = 0.93\n",
      "peer_performance_score & sector_discrimination_score = 0.92\n",
      "peer_performance_score & era_funding_bias = 0.93\n",
      "peer_performance_score & economic_cycle_impact = 0.93\n",
      "peer_performance_score & systemic_bias_accumulation = 0.94\n",
      "relationships_count & network_connectivity = 0.94\n",
      "relationships_count & team_network_strength = 1.00\n",
      "network_connectivity & team_network_strength = 0.94\n",
      "milestones_per_year & organic_growth_indicator = 1.00\n",
      "is_milestone_active & milestone_frequency = 0.96\n",
      "has_logo & digital_presence_score = 1.00\n",
      "has_logo & team_digital_maturity = 1.00\n",
      "digital_presence_score & team_digital_maturity = 1.00\n",
      "has_description & description_length = 0.93\n",
      "has_description & text_sophistication = 0.91\n",
      "has_description & team_communication_quality = 0.91\n",
      "content_richness & ecosystem_engagement = 1.00\n",
      "content_richness & operational_sophistication = 1.00\n",
      "description_length & text_sophistication = 0.96\n",
      "description_length & team_communication_quality = 0.96\n",
      "text_sophistication & team_communication_quality = 1.00\n",
      "time_to_first_funding_days & time_to_first_funding_years = 1.00\n",
      "days_since_last_funding & time_in_current_stage = 1.00\n",
      "ecosystem_engagement & operational_sophistication = 1.00\n",
      "strategic_positioning & state_funding_bias = 0.94\n",
      "strategic_positioning & regional_funding_disadvantage = 0.92\n",
      "strategic_positioning & urban_rural_bias = 0.94\n",
      "strategic_positioning & industry_funding_bias = 0.94\n",
      "strategic_positioning & sector_discrimination_score = 0.92\n",
      "strategic_positioning & era_funding_bias = 0.94\n",
      "strategic_positioning & economic_cycle_impact = 0.94\n",
      "strategic_positioning & systemic_bias_accumulation = 0.95\n",
      "undercap_survival_months & undercap_longevity_score = 0.94\n",
      "undercap_survival_months & undercap_peer_avg_survival = 0.96\n",
      "undercap_survival_months & company_age_years_safe = 1.00\n",
      "bootstrap_efficiency & high_milestone_minimal_funding = 0.91\n",
      "undercap_longevity_score & company_age_years_safe = 0.94\n",
      "undercap_peer_count & undercap_peer_median_milestones = 0.97\n",
      "undercap_peer_avg_survival & company_age_years_safe = 0.96\n",
      "undercap_geographic_density & region_startup_count = 0.91\n",
      "undercap_geographic_density & geographic_cluster_strength = 0.91\n",
      "funding_stage_numeric & stage_progression_rate = 0.96\n",
      "funding_stage_numeric & stage_transition_velocity = 0.96\n",
      "funding_stage_numeric & expected_age_for_stage = 1.00\n",
      "funding_stage_numeric & stage_vs_industry_expectation = 0.98\n",
      "funding_stage_numeric & industry_progression_percentile = 0.98\n",
      "funding_stage_numeric & sector_stage_advantage = 0.98\n",
      "stage_progression_rate & stage_transition_velocity = 1.00\n",
      "stage_progression_rate & expected_age_for_stage = 0.96\n",
      "stage_progression_rate & stage_vs_industry_expectation = 0.94\n",
      "stage_progression_rate & industry_progression_percentile = 0.94\n",
      "stage_progression_rate & sector_stage_advantage = 0.94\n",
      "stage_transition_velocity & expected_age_for_stage = 0.96\n",
      "stage_transition_velocity & stage_vs_industry_expectation = 0.94\n",
      "stage_transition_velocity & industry_progression_percentile = 0.94\n",
      "stage_transition_velocity & sector_stage_advantage = 0.94\n",
      "expected_age_for_stage & stage_vs_industry_expectation = 0.98\n",
      "expected_age_for_stage & industry_progression_percentile = 0.98\n",
      "expected_age_for_stage & sector_stage_advantage = 0.98\n",
      "stage_vs_industry_expectation & industry_progression_percentile = 1.00\n",
      "stage_vs_industry_expectation & sector_stage_advantage = 1.00\n",
      "industry_progression_percentile & sector_stage_advantage = 1.00\n",
      "state_funding_bias & regional_funding_disadvantage = 0.98\n",
      "state_funding_bias & urban_rural_bias = 1.00\n",
      "state_funding_bias & industry_funding_bias = 1.00\n",
      "state_funding_bias & era_funding_bias = 1.00\n",
      "state_funding_bias & economic_cycle_impact = 1.00\n",
      "state_funding_bias & systemic_bias_accumulation = 0.95\n",
      "regional_funding_disadvantage & urban_rural_bias = 0.98\n",
      "regional_funding_disadvantage & industry_funding_bias = 0.98\n",
      "regional_funding_disadvantage & era_funding_bias = 0.98\n",
      "regional_funding_disadvantage & economic_cycle_impact = 0.98\n",
      "regional_funding_disadvantage & systemic_bias_accumulation = 0.94\n",
      "urban_rural_bias & industry_funding_bias = 1.00\n",
      "urban_rural_bias & era_funding_bias = 1.00\n",
      "urban_rural_bias & economic_cycle_impact = 1.00\n",
      "urban_rural_bias & systemic_bias_accumulation = 0.95\n",
      "industry_funding_bias & era_funding_bias = 1.00\n",
      "industry_funding_bias & economic_cycle_impact = 1.00\n",
      "industry_funding_bias & systemic_bias_accumulation = 0.96\n",
      "sector_discrimination_score & systemic_bias_accumulation = 0.99\n",
      "era_funding_bias & economic_cycle_impact = 1.00\n",
      "era_funding_bias & systemic_bias_accumulation = 0.96\n",
      "economic_cycle_impact & systemic_bias_accumulation = 0.96\n",
      "state_success_rate & state_risk_score = 1.00\n",
      "state_success_rate & state_undercap_concentration = 1.00\n",
      "state_success_rate & state_avg_funding = 0.95\n",
      "state_success_rate & geographic_opportunity_score = 0.98\n",
      "state_success_rate & state_investment_gap = 0.95\n",
      "state_success_rate & regional_arbitrage_potential = 0.98\n",
      "state_risk_score & state_undercap_concentration = 1.00\n",
      "state_risk_score & state_avg_funding = 0.96\n",
      "state_risk_score & geographic_opportunity_score = 0.99\n",
      "state_risk_score & state_investment_gap = 0.96\n",
      "state_risk_score & regional_arbitrage_potential = 0.97\n",
      "region_startup_count & geographic_cluster_strength = 1.00\n",
      "state_undercap_concentration & state_avg_funding = 0.96\n",
      "state_undercap_concentration & geographic_opportunity_score = 0.99\n",
      "state_undercap_concentration & state_investment_gap = 0.96\n",
      "state_undercap_concentration & regional_arbitrage_potential = 0.98\n",
      "state_avg_funding & geographic_opportunity_score = 0.99\n",
      "state_avg_funding & state_investment_gap = 1.00\n",
      "state_avg_funding & regional_arbitrage_potential = 0.92\n",
      "geographic_opportunity_score & state_investment_gap = 0.99\n",
      "geographic_opportunity_score & regional_arbitrage_potential = 0.97\n",
      "state_investment_gap & regional_arbitrage_potential = 0.92\n",
      "\n",
      "Features with high skewness (|skew| > 1):\n",
      "lat                             -2.779488\n",
      "lng                              1.029443\n",
      "founded_year                    -5.724393\n",
      "company_age_years                3.121951\n",
      "funding_total_usd               96.476883\n",
      "                                  ...    \n",
      "state_undercap_concentration    -1.341323\n",
      "state_avg_funding                1.698416\n",
      "geographic_opportunity_score    -1.426932\n",
      "state_investment_gap            -1.698416\n",
      "regional_arbitrage_potential    -1.130109\n",
      "Length: 93, dtype: float64\n",
      "\n",
      "Feature quality summary:\n",
      "Features ready for modeling: 157\n",
      "Features needing attention: 2\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric features\n",
    "numeric_features = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Infinite values check\n",
    "infinite_values_check = df[numeric_features].isin([np.inf, -np.inf]).sum()\n",
    "print(\"Features with infinite values:\")\n",
    "print(infinite_values_check[infinite_values_check > 0])\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "df[numeric_features] = df[numeric_features].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Extreme outliers check using IQR method\n",
    "outlier_counts = {}\n",
    "for col in numeric_features:\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    outliers = ((df[col] < (q1 - 3*iqr)) | (df[col] > (q3 + 3*iqr))).sum()\n",
    "    if outliers > 0:\n",
    "        outlier_counts[col] = outliers\n",
    "print(\"\\nFeatures with extreme outliers (IQR > 3*IQR rule):\")\n",
    "print(outlier_counts)\n",
    "\n",
    "# Target correlation analysis\n",
    "if 'failure_risk' in df.columns:\n",
    "    # Get correlation with target\n",
    "    corr_with_target = df[numeric_features + ['failure_risk']].corr()['failure_risk'].drop('failure_risk')\n",
    "    \n",
    "    # Convert to Series if it's a DataFrame\n",
    "    if isinstance(corr_with_target, pd.DataFrame):\n",
    "        corr_with_target = corr_with_target.iloc[:, 0] if len(corr_with_target.columns) > 0 else corr_with_target.iloc[0]\n",
    "    \n",
    "    # Sort by absolute correlation\n",
    "    top_corr_indices = corr_with_target.abs().sort_values(ascending=False).head(20).index\n",
    "    top_corr = corr_with_target[top_corr_indices]\n",
    "    \n",
    "    print(\"\\nTop 20 features correlated with failure_risk:\")\n",
    "    print(top_corr)\n",
    "else:\n",
    "    print(\"\\nTarget column 'failure_risk' not found. Skipping correlation analysis.\")\n",
    "\n",
    "# Alternative simpler approach for correlation analysis:\n",
    "if 'failure_risk' in df.columns:\n",
    "    print(\"\\nAlternative approach - Top 20 features correlated with failure_risk:\")\n",
    "    corr_results = df[numeric_features].corrwith(df['failure_risk']).sort_values(key=abs, ascending=False).head(20)\n",
    "    print(corr_results)\n",
    "\n",
    "# Multicollinearity assessment (|corr| > 0.9)\n",
    "high_corr_pairs = []\n",
    "corr_matrix_abs = df[numeric_features].corr().abs()\n",
    "for i in range(len(corr_matrix_abs.columns)):\n",
    "    for j in range(i + 1, len(corr_matrix_abs.columns)):\n",
    "        if corr_matrix_abs.iloc[i, j] > 0.9:\n",
    "            high_corr_pairs.append((corr_matrix_abs.columns[i], corr_matrix_abs.columns[j], corr_matrix_abs.iloc[i, j]))\n",
    "print(\"\\nHighly correlated feature pairs (|corr| > 0.9):\")\n",
    "for f1, f2, val in high_corr_pairs:\n",
    "    print(f\"{f1} & {f2} = {val:.2f}\")\n",
    "\n",
    "# Feature distribution analysis using skewness\n",
    "feature_skewness = df[numeric_features].skew()\n",
    "print(\"\\nFeatures with high skewness (|skew| > 1):\")\n",
    "print(feature_skewness[abs(feature_skewness) > 1])\n",
    "\n",
    "# Summary of feature quality\n",
    "ready_features = [f for f in numeric_features if f not in infinite_values_check[infinite_values_check > 0].index.tolist()]\n",
    "need_attention = list(set(numeric_features) - set(ready_features))\n",
    "print(\"\\nFeature quality summary:\")\n",
    "print(f\"Features ready for modeling: {len(ready_features)}\")\n",
    "print(f\"Features needing attention: {len(need_attention)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef6c4b",
   "metadata": {},
   "source": [
    "## Step 2: Project-Specific Feature Validation\n",
    "\n",
    "```\n",
    "ALGORITHM: Project Goal Alignment Validation\n",
    "1. Validate features support project objectives:\n",
    "   - Under-capitalized startup analysis capability\n",
    "   - Risk profiling and clustering readiness\n",
    "   - Geographic heatmap data completeness\n",
    "   - Month 2 ML model preparation\n",
    "\n",
    "2. Project Alignment Checks:\n",
    "   - undercap_feature_coverage = features_supporting_undercap_analysis\n",
    "   - risk_profiling_readiness = features_for_clustering_and_personas\n",
    "   - heatmap_data_completeness = geographic_features_for_dashboard\n",
    "   - ml_model_preparation = target_variables_and_feature_quality\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- Under-cap analysis feature inventory: \"X features ready for under-cap focus\"\n",
    "- Risk profiling feature set: \"X features ready for clustering\"\n",
    "- Heatmap data validation: \"Geographic coverage for X% of companies\"\n",
    "- ML readiness assessment: \"Dataset ready for Month 2 modeling\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4c7facc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features ready for under-cap focus: 3\n",
      "List of under-cap related features: ['under_capitalized', 'geographic_opportunity_score', 'regional_arbitrage_potential']\n",
      "\n",
      "Features ready for clustering and risk profiling: 15\n",
      "List of risk-related features: ['failure_risk', 'risk_tier', 'risk_tier_label', 'country_risk_mean', 'country_risk_confidence', 'industry_risk_mean', 'industry_risk_confidence', 'stage_risk_mean', 'geo_industry_risk', 'experience_risk_score', 'risk_vs_country_peers', 'risk_vs_industry_peers', 'risk_vs_stage_peers', 'progression_risk_score', 'state_risk_score']\n",
      "\n",
      "Geographic coverage for dashboard: 0.00% of companies\n",
      "Geographic features included: ['state_code', 'city', 'region', 'funding_velocity_category', 'funding_velocity', 'age_funding_velocity', 'bootstrap_milestone_velocity', 'stage_transition_velocity', 'state', 'state_median_funding', 'state_funding_bias', 'region_avg_funding', 'regional_funding_disadvantage', 'state_population', 'state_startup_density', 'state_success_rate', 'state_risk_score', 'region_startup_count', 'region_avg_funding_region', 'region_success_rate', 'metro_area_flag', 'metro_area_advantage', 'state_undercap_concentration', 'state_avg_funding', 'state_investment_gap', 'regional_arbitrage_potential']\n",
      "\n",
      "Dataset ready for Month 2 modeling: True\n"
     ]
    }
   ],
   "source": [
    "# Under-capitalized analysis features\n",
    "undercap_features = [f for f in df.columns if 'under_cap' in f or 'geographic_opportunity' in f or 'regional_arbitrage' in f]\n",
    "undercap_feature_coverage = len(undercap_features)\n",
    "print(f\"Features ready for under-cap focus: {undercap_feature_coverage}\")\n",
    "print(\"List of under-cap related features:\", undercap_features)\n",
    "\n",
    "# Risk profiling and clustering readiness\n",
    "risk_features = [f for f in df.columns if 'risk' in f or 'failure_risk' in f or 'risk_tier' in f or 'state_risk_score' in f]\n",
    "risk_profiling_readiness = len(risk_features)\n",
    "print(f\"\\nFeatures ready for clustering and risk profiling: {risk_profiling_readiness}\")\n",
    "print(\"List of risk-related features:\", risk_features)\n",
    "\n",
    "# Heatmap and geographic coverage validation\n",
    "geo_features = [f for f in df.columns if 'state' in f or 'region' in f or 'city' in f or 'metro' in f]\n",
    "heatmap_data_completeness = df[geo_features].notna().all(axis=1).mean() * 100\n",
    "print(f\"\\nGeographic coverage for dashboard: {heatmap_data_completeness:.2f}% of companies\")\n",
    "print(\"Geographic features included:\", geo_features)\n",
    "\n",
    "# ML readiness assessment\n",
    "# Check that target exists and numeric features are prepared\n",
    "target_ready = 'failure_risk' in df.columns\n",
    "numeric_ready = len([f for f in numeric_features if f not in infinite_values_check[infinite_values_check > 0].index.tolist()]) > 0\n",
    "ml_model_preparation = target_ready and numeric_ready\n",
    "print(f\"\\nDataset ready for Month 2 modeling: {ml_model_preparation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa99fcc",
   "metadata": {},
   "source": [
    "## Step 3: Enhanced Dataset Output & Documentation\n",
    "\n",
    "```\n",
    "ALGORITHM: Feature Engineering Output Generation\n",
    "1. Create comprehensive feature-engineered dataset:\n",
    "   - Include all original features + new engineered features\n",
    "   - Add feature documentation and metadata\n",
    "   - Generate feature importance preliminary rankings\n",
    "   - Create handoff documentation for EDA phase\n",
    "\n",
    "2. Output Generation:\n",
    "   - enhanced_feature_dataset = original_features + engineered_features\n",
    "   - feature_documentation = descriptions_and_calculation_methods\n",
    "   - feature_importance_preview = correlation_based_initial_rankings\n",
    "   - eda_handoff_requirements = next_phase_analysis_requirements\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "- companies_feature_engineering.csv with 100+ features\n",
    "- Feature documentation reference guide\n",
    "- Preliminary feature importance rankings\n",
    "- EDA phase requirements and recommendations\n",
    "```\n",
    "\n",
    "Again this all should be documented in markdown format that is included in this repo. Please do so ASAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6884c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emily\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\emily\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# Ensure the target directory exists\n",
    "output_dir = '../processed_data/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create enhanced dataset: original + engineered features\n",
    "enhanced_feature_dataset = df.copy()\n",
    "\n",
    "# Generate feature metadata/documentation\n",
    "feature_documentation = pd.DataFrame({\n",
    "    'feature_name': df.columns,\n",
    "    'data_type': df.dtypes.astype(str),\n",
    "    'description': ['' for _ in df.columns],           # Fill manually or later programmatically\n",
    "    'calculation_method': ['' for _ in df.columns]     # Fill manually or later\n",
    "})\n",
    "\n",
    "# Preliminary feature importance using correlation with target\n",
    "if 'failure_risk' in df.columns:\n",
    "    numeric_features = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    numeric_features = [f for f in numeric_features if f != 'failure_risk']\n",
    "    feature_documentation['prelim_target_correlation'] = feature_documentation['feature_name'].map(\n",
    "        df[numeric_features].corrwith(df['failure_risk']).to_dict()\n",
    "    )\n",
    "else:\n",
    "    feature_documentation['prelim_target_correlation'] = None\n",
    "\n",
    "# Save outputs to processed_data folder\n",
    "enhanced_feature_dataset.to_csv(os.path.join(output_dir, 'companies_feature_engineering.csv'), index=False)\n",
    "feature_documentation.to_csv(os.path.join(output_dir, 'feature_documentation_reference.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
